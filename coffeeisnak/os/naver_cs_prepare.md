# 개념을 정말 간단히만 정리하기

## CS 요약 정리

#### 1. 운영체제 (OS)

- 프로세스 vs 스레드
    - 프로세스: 실행 중인 프로그램, 독립적인 메모리 공간.
    - 스레드: 프로세스 내에서 실행되는 작업 단위, 메모리 공간 공유.

- 멀티스레딩
    - 장점: 자원 공유로 메모리 절약, 응답성 향상.
    - 단점: 동기화 문제, 데드락 발생 가능. 

- 동기화 (Synchronization): 여러 스레드가 동시에 공유 자원(변수, 메모리)에 접근할 때 데이터의 일관성을 유지하기 위한 기술
    - 스레드들이 동시에 하나의 자원에 접근해서 값을 바꾸면 경쟁 조건(Race Condition)이 발생할 수 있음.
    - 락(Lock), 뮤텍스(Mutex), 세마포어(Semaphore) 같은 걸로 한 번에 하나의 스레드만 자원에 접근하도록 제어

- 데드락 (Deadlock): 두 개 이상의 스레드나 프로세스가 서로가 가진 자원을 기다리면서 무한 대기 상태에 빠지는 현상
    - 데드락 발생 조건 (4가지 전부 만족해야 함)
        - 상호 배제(Mutual Exclusion): 자원을 한 번에 하나의 스레드만 사용 가능
        - 점유와 대기(Hold and Wait): 자원을 가진 채로 다른 자원을 기다림
        - 비선점(No Preemption): 자원을 강제로 빼앗을 수 없음
        - 순환 대기(Circular Wait): 자원을 기다리는 순환 고리가 있음

- 락 (Lock): 공유 자원에 접근할 때 하나의 스레드만 접근 가능하게 잠그는 메커니즘
    - 임계 구역(Critical Section)에서 사용됨
    - 스레드가 락을 걸면 다른 스레드는 대기해야 함
    - 락을 해제하지 않으면 데드락 가능성 있음

- 뮤텍스 (Mutex): Mutual Exclusion(상호 배제)의 줄임말
    - 락과 비슷하지만 스레드 간에 소유권이 더 엄격해
    - 한 번에 하나의 스레드만 락을 얻을 수 있음
    - 해제는 락을 소유한 스레드만 가능
    - 프로세스 간 동기화도 가능 (락은 스레드 간 제한됨)

- 세마포어 (Semaphore): 카운터 기반 락
    - 특정 자원에 허용할 수 있는 동시 접근 수를 지정
    - 카운트가 0이 되면 대기 상태, 자원이 반납되면 카운트가 증가
    - Binary Semaphore → 0과 1만 가능 → 뮤텍스처럼 동작
    - Counting Semaphore → N개의 리소스를 관리할 때 사용


- 모니터 (Monitor): 락 + 조건 변수(Condition Variable)를 결합한 고급 구조
    - 스레드 간 락과 대기/알림을 효율적으로 관리
    - 락으로 보호되는 자원과 대기큐가 내부에 포함됨
    - Java의 synchronized나 Python의 threading.Condition()이 모니터 개념

- 문맥 교환(Context Switching)
    - CPU가 다른 프로세스로 전환될 때 발생. PCB 정보 저장/복구 필요.
    - 오버헤드 있음.

- PCB(Process Control Block): 프로세스의 상태를 저장하는 데이터 구조
    - 프로세스의 모든 정보를 담고 있는 데이터 블록
    - 운영체제가 각 프로세스를 관리하기 위해 반드시 필요해.
    - 프로세스 상태, 프로그램 카운터(PC), CPU 레지스터 값, 메모리 관리 정보, 프로세스 ID(PID), I/O 상태 정보 등 저장
    - 문맥 교환: CPU가 현재 실행 중인 프로세스 상태를 PCB에 저장하고 다른 프로세스의 PCB를 불러와서 그 상태로 복구하는 작업 => 문맥 교환의 오버헤드(시간 손실)가 발생하는 이유

- 동기 / 비동기
    - 동기: 요청한 작업이 끝날 때까지 기다림.
    - 비동기: 작업 요청 후 기다리지 않고 다음 작업 수행.

- 동기(Synchronous): 요청을 보내고 결과가 돌아올 때까지 기다린다
    - 요청한 작업이 끝나야 그다음 동작을 함
    - 블로킹 방식이 많음 (멈춰서 기다림)
    - 직관적이고 단순함, 처리 속도는 느릴 수 있음 (대기 시간 발생)

- 비동기(Asynchronous): 요청을 보내고 바로 다음 작업을 진행한다
    - 결과가 오면 나중에 따로 처리
    - 논블로킹 방식이 많음 (멈추지 않고 진행)
    - 빠른 처리가 가능, 복잡도는 상대적으로 높음 (콜백, 이벤트 처리 등)

- 이벤트 리스너(Event Listener): 이벤트가 발생하면 실행되는 함수(핸들러)를 등록해 놓는 것
    - 이벤트가 발생할 때까지 대기 상태

- 콜백 함수(Callback Function): 다른 함수에 인자로 전달되어, 특정 시점에 실행되는 함수
    - 비동기 처리에서 자주 사용

- 비동기 처리 흐름 (기본 개념)
    - 기본 순서
        1. 요청 발생: 시간이 오래 걸리는 작업 요청 (예: 서버 요청, 타이머 등)
        2. 메인 로직은 그대로 실행 계속: 기다리지 않고 다음 코드 실행 (논블로킹)
        3. 이벤트가 발생하거나 작업이 완료되면 => 등록한 콜백 함수 또는 이벤트 리스너가 호출됨
        4. 콜백 함수가 호출돼서 후처리 실행
    - 콜백과 이벤트 리스너 차이 흐름
        - 콜백 함수 흐름: 특정 비동기 작업(함수)에 콜백 전달 → 완료되면 콜백 실행
        - 이벤트 리스너 흐름: 특정 이벤트를 리스너에 등록 → 이벤트가 발생하면 실행

- 비동기 요약
    - 콜백은 비동기 함수 완료 후 실행되는 함수
    - 이벤트 리스너는 이벤트가 발생했을 때 반응하는 함수
    - 둘 다 메인 로직과 병렬로 동작해서 프로그램이 멈추지 않음 (비동기)

- 블로킹 / 논블로킹
    - 블로킹: 결과가 나올 때까지 멈춤.
    - 논블로킹: 결과가 나오지 않아도 바로 리턴.

- 데드락(Deadlock)
    - 발생 조건
        - 상호 배제: 하나 이상의 자원을 둘 이상의 프로세스가 이용 불가
        - 점유와 대기: 자원을 점유한 프로세스가 다른 자원을 요청
        - 비선점: 다른 프로세스의 자원을 뺏아올 수 없는 상태
        - 순환 대기: cyclic한 요청 및 대기 구조
    - 예방 방법
        - 상호 배제 부정: 자원을 공유 가능하게 만들기 (현실적으로 어려움)
        - 점유와 대기 부정: 프로세스가 자원을 모두 확보한 후 실행. → 못 하면 대기하지 않고 점유한 자원 반납하고 재시도. (기아 상태, 본인의 우선 순위가 낮아 자원을 기다리며 영원히 실행되지 못하는 상태 발생 위험 있음) => 해결법: Aging 기법으로 우선순위를 점점 높여서 해결
        - 비선점 부정: 자원을 빼앗을 수 있도록 함. → 다른 프로세스가 점유 중이면 자원 강제로 회수하고 다른 작업으로 이동
        - 순환 대기 부정 (자원 순서 지정): 자원에 고유한 순서 번호를 부여하고, 항상 번호가 높은 자원을 먼저 요청하도록 한다. → 순환 대기를 원천적으로 차단 가능
        - 타임아웃 설정: 자원을 획득하지 못한 상태가 일정 시간 이상 지속되면, 자원 점유를 포기하고 다시 시도
        - 은행원 알고리즘 (Banker's Algorithm): 은행이 대출할 때 고객이 파산하지 않을 수준만큼 대출해주는 것처럼 시스템이 안정 상태에서만 자원을 할당하는 방법 (실제 구현 복잡함)





#### 2. 네트워크

- OSI 7계층
    - 물리 → 데이터 링크 → 네트워크 → 전송 → 세션 → 표현 → 응용

1. 물리 계층 (Physical Layer)

- 케이블과 전파, 신호를 다루는 하드웨어 => 우리가 보내는 0과 1의 비트가 전기 신호나 빛 신호로 변환되어 케이블을 타고 이동
- 진짜 선, 리피터, 허브 같은 물리적 장치가 있음. => 와이파이 전파, 랜선 안의 신호 등


2. 데이터 링크 계층 (Data Link Layer)

- 직접 연결된 두 장치 간에 데이터 전송 담당
- 내 컴퓨터 → 스위치 → 라우터처럼 가까운 이웃끼리 통신
- MAC 주소(하드웨어 주소)를 사용해서 목적지 찾음
- 오류가 나면 바로 잡아줌 (CRC로 오류 검출) => 내 컴퓨터가 같은 네트워크 안의 프린터랑 통신할 때


3. 네트워크 계층 (Network Layer)

- 장거리 이동과 경로 선택(라우팅)을 담당
- 데이터를 패킷 단위로 나눠서 전송하고, IP 주소를 보고 어디로 가야 하는지 결정함
- 라우터가 여기에 해당 => 서울에서 부산까지 택배 보낼 때, 어느 고속도로로 갈지 정하는 것


4. 전송 계층 (Transport Layer)

- 종단 간(End-to-End) 통신을 보장!
- 내가 보낸 데이터가 진짜 안전하게 잘 도착했는지 체크
- TCP는 신뢰성(확인, 재전송), UDP는 빠르게만 보내고 신뢰성은 없음
- 예시
    - 카톡 메세지 보낼 때, TCP라면 읽었는지 확인하고,
    - UDP라면 게임 총알처럼 빠르게 보내기만 함


5. 세션 계층 (Session Layer)

- 연결을 유지하고 세션을 관리함!
- 서버와 클라이언트 간의 대화방을 열고 닫는 역할
- 연결이 끊기면 재연결하거나 동기화함


6. 표현 계층 (Presentation Layer)

- 서로 다른 시스템 간 데이터 형식 맞춰주기
- 데이터를 암호화/복호화, 압축하거나 인코딩 변환(EBCDIC → ASCII)
- 포맷을 통일시켜서 잘 읽히게 함


7. 응용 계층 (Application Layer)

- 사용자가 직접 사용하는 프로그램 영역!
- 우리가 쓰는 웹 브라우저(HTTP), 메일(POP, SMTP) 등
- 사용자가 데이터를 보내고 받는 출입구 같은 곳!


- CRC (Cyclic Redundancy Check, 순환 중복 검사): 데이터가 전송 중에 오류가 생겼는지 검사하는 방법
    - 데이터를 전송하기 전에 특정 계산(나눗셈 연산)을 해서 검사 값(Checksum)을 붙여서 보냄.
    - 받는 쪽에서 다시 똑같은 계산을 해봐서 => 검사 값이 같으면 문제 없음, 검사 값이 다르면 데이터가 손상됐다

- EBCDIC → ASCII 변환: 둘 다 문자를 숫자로 변환하는 문자 인코딩 방식
    - ASCII (아스키 코드): 영어 알파벳을 숫자로 변환하는 가장 기본적인 코드
    - EBCDIC (Extended Binary Coded Decimal Interchange Code): IBM이 만든 옛날 인코딩 방식
        - ASCII랑 숫자 매핑이 다름 → 호환 안 됨
    - 서로 다른 시스템(IBM 메인프레임 ↔ PC)이 데이터를 주고받을 때 EBCDIC ↔ ASCII 변환이 필요

- TCP vs UDP
    - TCP
        - 연결 지향: 느리지만 확실하고 안전하게 전달함, 중요 데이터 보내기 전 연결을 먼저 만든다 = 연결 지향(Connection-Oriented)
        - 신뢰성 보장
        - 순서 보장(3-way handshake): TCP에서 서버랑 클라이언트가 서로 약속을 맺는 과정, 서버 클라이언트간 3번 주고받아서(3-way) 연결을 확실하게 만들기 때문에 붙은 이름
    - UDP
        - 비연결(연결 안 함) 방식, 대신 속도가 엄청 빠름
        - 속도 빠름
        - 신뢰성 없음 (스트리밍, DNS 등)

- HTTP vs HTTPS
    - HTTP: HyperText Transfer Protocol의 약자
        - 웹사이트에 접속할 때 쓰는 통신 규칙(프로토콜)
        - 비연결성: 한 번 요청하고 응답이 오면 서버와 연결이 바로 끊김, 요청-응답 단위로만 통신하고, 계속 연결을 유지하지 않음
        - 무상태성: 서버가 클라이언트의 이전 정보를 기억하지 않음
    - HTTPS: HTTP Secure, 즉 보안이 추가된 HTTP
        - SSL/TLS라는 암호화 기술이 추가된 버전
        - 데이터를 암호화해서 안전하게 전송 => 누가 중간에 데이터를 훔쳐가도 내용을 볼 수 없음.
        - SSL/TLS: 데이터를 보낼 때 자물쇠 채워서 보내는 기술, 내 정보(아이디, 비번, 카드번호 등)가 중간에서 해킹당해도 알아볼 수 없게 암호화

- 쿠키 vs 세션
    - 쿠키: 클라이언트 저장, 크기/보안 제한.
        - 클라이언트(사용자 컴퓨터, 브라우저)에 저장하는 데이터 조각
        - 웹사이트가 사용자 정보를 기억하려고 클라이언트 쪽에 저장, 자동 로그인 등에 사용
        - 저장 위치: 클라이언트 (브라우저에 저장됨)
        - 용량 제한: 작음 (4KB 정도)
        - 보안: 노출 위험이 있음 (클라이언트에 저장되어서 조작 가능)
        - 사용 예시: 자동 로그인, 장바구니 정보 저장
    - 세션: 서버 저장, 상대적으로 보안이 좋음.
        - 서버가 사용자별로 따로 정보를 관리하는 방식
        - 사용자가 로그인하면 서버가 서버에 정보를 저장하고 세션 ID를 사용자한테 줌 → 사용자는 다음 요청에 이 ID만 보내면 됨
        - 저장 위치: 서버 (서버 메모리에 저장)
        - 용량 제한: 서버 성능에 따라 다름
        - 보안: 서버에서 관리하니까 상대적으로 안전
        - 사용 예시: 로그인 유지, 사용자 정보 보호

- DNS 동작 과정
    - 브라우저에 도메인 주소 입력 => 컴퓨터는 이걸 보고 IP 주소를 알아내야 서버에 연결할 수 있음.
    - 먼저 로컬 캐시 확인 => 예전에 접속했던 기록이 있다면 → 바로 IP 주소 반환 => 없으면? → DNS 서버에게 물어봄
    - DNS 서버(네임서버)에 요청 => 내가 속한 인터넷 제공업체(ISP)의 DNS 서버가 첫 번째로 받음 => 이 서버가 모르겠으면 상위 DNS 서버에 요청을 보냄.
    - 계층 구조로 상위 네임서버에 차례차례 문의 => 루트 네임서버 → .com 네임서버 → naver.com 네임서버 순으로 진행
    - 마지막 권한 DNS 서버가 최종 IP 주소를 알려줌
    - 받은 IP 주소로 접속 => 이제 브라우저가 ip 주소에 접속함

- Domain Name: 사람이 보기 쉬운 주소 (www.naver.com)
- IP 주소: 컴퓨터가 통신하는 숫자 주소 (125.209.222.141)
- DNS 서버(네임서버): 이름을 IP로 바꿔주는 서버
- 계층적 구조: 루트 → 최상위(TLD) → 권한(Authoritative)

- DNS 공격 & 보안 개념
    - DNS 스푸핑: 가짜 IP 주소를 응답하여 사용자를 피싱 사이트로 유도
    - DNS 캐싱 포이즈닝: DNS 서버 캐시에 악성 데이터를 저장시켜서 잘못된 IP로 연결 유도
    - HTTPS가 중요한 이유와도 연결

- 로드 밸런싱 (Load Balancing): 서버 트래픽을 여러 서버에 분산
    - L4 (전송 계층)
        - 네트워크 계층(전송 계층)에서 분산
        - 클라이언트 IP, 포트 기반
        - 빠르지만 단순함, AWS ELB (네트워크 로드 밸런서)
    - L7 로드 밸런서
        - 애플리케이션 계층에서 분산
        - URL, 쿠키, 헤더 기반으로 분산 가능

- REST API 개념
    - REST (Representational State Transfer)
        - 자원을 URI로 식별하고, 상태는 HTTP 메서드(GET, POST 등)로 처리
        - 무상태성, 클라이언트-서버 구조 원칙




#### 3. 자료구조

- 배열 vs 연결 리스트
    - 배열: 인덱스 접근 O(1), 크기 고정.
    - 연결 리스트: 삽입/삭제 O(1), 탐색 O(n).

- 스택 / 큐
    - 스택: LIFO (후입선출), DFS.
    - 큐: FIFO (선입선출), BFS.

- 힙 (Heap)
    - 최소/최대 힙: 우선순위 큐 구현, 삽입/삭제 O(log n).
    - 트리 / 이진 탐색 트리트리: 계층적 자료구조.
    - 탐색은 느림

- BST (이진 탐색 트리: Binary Search Tree): 왼쪽 < 루트 < 오른쪽, 탐색 O(log n).
    - 왼쪽 자식은 루트보다 작고, 오른쪽 자식은 루트보다 큰 구조를 유지하는 트리
    - 탐색이 빠름 => 정렬된 형태 유지하기 때문에 => 탐색, 삽입, 삭제 모두 평균 O(log n) 시간
    - 단점: 한쪽으로 편향되면 성능이 떨어질 수 있음 최악 O(n)

- 그래프 / DFS / BFS
    - 그래프: 정점과 간선으로 구성.
    - DFS: 깊이 우선 탐색, 스택/재귀 사용.
    - BFS: 너비 우선 탐색, 큐 사용.

- 해시테이블
    - 키를 해시함수로 변환하여 인덱스에 저장.
    - 평균 검색 O(1), 충돌 해결 (체이닝, 개방 주소법).


#### 4. 알고리즘

1. 정렬

- 퀵 정렬: 분할 정복, 평균 O(n log n), 최악 O(n^2), 불안정.
- 머지 정렬: 항상 O(n log n), 안정 정렬.
- 힙 정렬: O(n log n), 불안정.


2. 탐색
    - 이진 탐색: 정렬된 데이터에서 중간값과 비교, O(log n).


3. 동적 계획법 

- (DP)부분 문제 저장 → 중복 계산 방지.
    - 탑다운: 재귀 + 메모이제이션.
    - 바텀업: 반복문으로 테이블 채움.


4. LIS (최장 증가 부분 수열)
    - 기본 DP: O(n^2)
    - 이진탐색(lower_bound): O(n log n)


5. 최소 공통 조상 (LCA)
    - 깊이 맞추고, 2^i 부모로 점프 (Binary Lifting).
    - 전처리 O(n log n), 쿼리 O(log n)


#### 5. 데이터베이스(DB)

- 트랜잭션과 ACID
    - 트랜잭션: 데이터베이스에서 작업의 최소 단위, 여러 작업이 하나의 덩어리로 묶여서, 모두 성공하거나, 하나라도 실패하면 전부 취소
    - 원자성 (Atomicity): 트랜잭션은 모두 실행되거나, 아예 안 되거나 둘 중 하나, 중간에 실패하면 전부 취소하고 롤백(Rollback)
    - 일관성 (Consistency): 트랜잭션 수행 전후에 데이터의 무결성이 유지되어야 함 => 규칙이나 제약조건을 어기지 않게!
    - 격리성 (Isolation): 동시에 여러 트랜잭션이 실행될 때 → 서로 영향을 주지 않고 독립적으로 실행되어야 함 => 다른 트랜잭션의 중간 결과를 보면 안 됨 => 동시성 제어 필요 (락 등 사용)
    - 지속성 (Durability): 트랜잭션이 커밋(Commit)되면 결과는 영구적으로 저장, 시스템이 고장나도 결과가 유지됨

- 트랜잭션 격리 수준 (Isolation Level)
    - Read Uncommitted: 커밋 안 된 것도 읽기 (가장 낮은 격리) => Dirty Read: 트랜잭션이 아직 확정(커밋)되지 않은 값을 읽음 → 롤백되면 데이터가 잘못됨
    - Read Committed: 커밋된 데이터만 읽음 => Non-Repeatable Read: 처음 읽은 후에, 다른 트랜잭션이 값을 바꿔버려서 같은 데이터를 다시 읽었더니 값이 달라질 수 잇음.
    - Repeatable Read: 트랜잭션 동안 동일 데이터 반복 보장 => Phantom Read: 조건에 맞는 새로운 행이 삽입/삭제돼서 동일한 쿼리를 다시 실행하면 결과 행 수가 바뀔 수 있음.
    - Serializable: 완전 직렬화 (가장 높은 격리) => 없음 (성능 저하)


- 인덱스
    - 덱스는 자료구조를 사용해서 데이터를 정렬하고 관리 => 대부분의 인덱스는 B+ 트리를 사용해서 효율적으로 찾음 => 데이터가 정렬돼 있어서 이진 탐색처럼 빠르게 이동 가능

- B- 트리
    - 다단계로 나뉜 균형 이진 탐색 트리(다진 트리)
    - 각 노드가 여러 개의 키와 포인터를 가짐
    - 데이터와 인덱스를 모두 내부 노드와 리프 노드에 저장 → 검색할 때 데이터가 내부 노드에도 있을 수 있고, 리프 노드에도 있을 수 있음 → 그래서 데이터가 흩어져 있어서 접근 속도가 다소 일정하지 않을 수 있음

- B+ 트리
    - B-트리에서 업그레이드 된 형태!
    - 데이터는 오직 리프 노드에만 저장
    - 내부 노드는 인덱스(키 값)만 저장해서 탐색 경로가 더 간단하고 일정함
    - 리프 노드가 연결 리스트처럼 연결되어 있어서 범위 검색이 빠름 -> 그래서 데이터베이스 인덱스에 가장 많이 사용됨

- B+ 트리로 인덱스를 쓰는 이유
    - 데이터가 전부 리프 노드에 있어서 탐색이 빠르고 일정
    - 범위 검색이 매우 효율적 (리프 노드가 순서대로 연결돼 있음)

- 정규화 vs 비정규화
    - 정규화
        - 중복 데이터를 최소화하고, 데이터 무결성 유지가 목적
        - 데이터베이스를 효율적으로 설계하는 방법
        - 테이블을 잘게 쪼갬 → 각각의 테이블이 단일한 의미만 가짐
        - 업데이트, 삽입, 삭제 시 오류 방지
    - 비정규화
        - 정규화된 테이블을 다시 통합하거나 중복을 허용하는 작업
        - 속도(성능) 향상이 목표 => 조인을 자주 해야 할 경우, 조인 비용이 커지니까 데이터를 합쳐서 저장하는 것
        - 읽기 작업이 많고 빠른 속도가 필요할 때 사용
        - 정규화가 지나치면 조인 연산이 많아져서 느려질 수 있고, 성능을 높이기 위해 약간의 중복을 허용하고 테이블을 합치기도 함

- 조인
    - INNER JOIN: 교집합.
    - OUTER JOIN: 한쪽 데이터 전부 가져옴.


#### 6. 컴퓨터 구조

- 메모리 계층 구조
    - 레지스터 → 캐시 → 메인 메모리 → 하드디스크.
    - 가까울수록 빠르고 비싸다.


- 캐시 메모리지역성의 원칙
    - 메모리 접근 패턴을 예측해서 효율적으로 데이터를 캐시에 저장하는 것
    - 시간 지역성(Temporal Locality): 최근에 사용한 데이터는 곧 또 사용될 가능성이 높다 => 그래서 한 번 가져온 데이터를 캐시에 저장하고 빠르게 다시 사용함
    - 공간 지역성(Spatial Locality): 지금 접근한 데이터 근처에 있는 데이터도 곧 사용할 가능성이 높다 => 예를 들어, 배열을 순서대로 읽는 경우 → 한 번에 묶어서 캐시에 저장
    - CPU와 메모리 사이 속도 차이를 완화하기 위해 사용

- 캐시 계층 구조
    - L1 캐시: CPU 내부, 가장 빠르고 작음 (용량 작음)
    - L2 캐시: CPU 내부 또는 외부, L1보다 느리지만 더 큼
    - L3 캐시: 멀티코어 CPU에서 공유, 느리지만 용량 큼

- 캐시가 없다면: CPU가 매번 메모리를 기다려야 해서 작업 속도가 크게 느려짐

- 가상 메모리: RAM(물리 메모리)가 부족하면 하드디스크 일부 공간을 메모리처럼 사용함
    - 페이징(Paging)과 세그멘테이션(Segmentation) 기법을 통해 가능
    - 필요한 메모리 공간만 조각내서 관리하고, 자주 안 쓰는 건 디스크로 옮김(Swap)
    - CPU가 다시 필요하면 하드디스크에서 메모리로 가져옴(페이지 폴트)

- 페이징 vs 세그멘테이션 (가상 메모리 관리 기법)
    - 페이징(Paging)
        - 고정 크기로 메모리를 나눔 (Page)
        - 외부 단편화 없음
        - 내부 단편화 존재 가능
    - 세그멘테이션(Segmentation)
        - 가변 크기로 메모리를 나눔 (Segment)
        - 프로그램 논리 단위에 따라 분할
        - 외부 단편화 발생 가능

- 캐시와 가상 메모리 차이
    - 목적: CPU와 메모리 속도 차이 완화 / 실제 메모리 부족 해결
    - 저장 위치: CPU와 메모리 사이 / 하드디스크와 메모리 사이
    - 주 기능: 자주 쓰는 데이터 미리 저장 / 물리 메모리 확장



#### 7. 기타 개념

- 시간 복잡도
    - O(1), O(log n), O(n), O(n log n), O(n^2)

- Stable / Unstable Sort
    - Stable: 같은 값이면 순서 유지 (머지, 버블).
    - Unstable: 순서 보장 안 함 (퀵, 힙).

- 해시 함수와 충돌 해결체이닝(리스트 연결), 개방 주소법(빈 공간 탐색).




## CS 문제 풀고 정리

1. 프로세스 스케줄링
    - CPU를 어떤 프로세스에게 언제 할당할지 결정하는 방식
    - 프로세스는 동시에 여러 개가 준비 상태일 수 있는데, CPU는 하나만 처리 가능
    - 운영체제가 어떤 프로세스를 우선 실행할지 스케줄링 알고리즘을 사용해 결정.

2. SJF / 다단계 큐
    - 비선점형: 실행 시작하면 끝까지 감
    - 선점형(SRTF): 더 짧은 게 오면 빼앗김!
    - SJF (Shortest Job First): 작업 시간이 짧은 프로세스를 우선 실행
        - 기아(Starvation) 발생 가능
        - 선점형, 비선점형 모두 가능
    - 다단계 큐 (Multi-Level Queue)
        - 프로세스를 우선순위별로 여러 개의 큐에 배치
        - 각 큐에 스케줄링 규칙이 다를 수 있음
        - 실시간 → FCFS
        - 백그라운드 → RR
            - 기아 상태가 발생할 수 있음 (우선순위가 낮은 큐는 계속 밀릴 수 있음)

3. 페이지 / 페이지 부재
    - 페이지(Page)
        - 가상 메모리를 일정한 크기(고정 크기)로 나눈 단위
        - 메모리를 효율적으로 관리하고, 외부 단편화를 없앰
        - CPU는 가상주소(Page 번호 + 오프셋)를 이용해 물리 메모리에 접근
    - 페이지 부재(Page Fault)
        - CPU가 필요한 페이지가 메모리에 없을 때 발생하는 예외 상황
        - 디스크에서 해당 페이지를 가져와 메모리에 올리고 프로세스를 재시작함
        - 페이지 폴트가 많아지면 시스템이 느려짐(스래싱)

4. 멀티코어 시스템에서 컨텍스트 스위칭
    - 멀티코어여도 하나의 코어는 한 순간 하나의 스레드/프로세스만 처리 가능 => 여전히 컨텍스트 스위칭 발생
    - 병렬 처리를 하더라도, 각 코어가 여러 프로세스를 스위칭해야 할 상황이 생김 (I/O 대기 등)

5. 비선점형 스케줄링과 다른 스케줄링
    - 비선점형 (Non-Preemptive): 프로세스가 CPU를 얻으면 자기가 끝날 때까지 계속 사용
        - 예시: FCFS, SJF(비선점형)
    - 선점형 (Preemptive): 우선순위가 높은 프로세스가 오면 현재 실행 중인 프로세스 중단 가능
        - 예시: Round Robin, SRTF(선점형 SJF), 선점형 우선순위 스케줄링

6. UDP 무결성과 TCP 재전송
    - UDP
        - 오류 검출(Checksum)은 한다!
        - 오류가 있으면 그냥 버림. 재전송 안 함!
    - TCP
        - 오류 검출하고, 손상/누락된 데이터가 있으면 재전송!
        - 수신자가 확인 응답(ACK)을 안 보내면 송신자가 재전송함.


7. 스레드 vs 프로세스 컨텍스트 스위칭 비용
    - 프로세스는 자신만의 메모리 공간, PCB, 커널 리소스를 전부 갖고 있어서 → 스위칭 시 메모리 매핑, 레지스터, 캐시 전부 저장/복구해야 함 → 무거움
    - 스레드는 프로세스 안에서 실행 → 메모리 공간 공유 → 스레드 컨텍스트만 바꾸면 됨 → 비용 적음!

8. 캐시의 쓰기 전략 (쓰기 / 읽기 전략)
    - 쓰기 전략(Write Policy)
        - Write-through: 데이터를 캐시와 메인 메모리에 동시에 기록 → 데이터 일관성 유지 O, 속도 느림
        - Write-back: 캐시에만 먼저 기록하고 나중에 메모리에 기록 → 속도 빠름, 하지만 전원 꺼지면 데이터 손실 위험 있음
    - 읽기 전략(Read Policy)
        - Read-through: 캐시 미스 시 메인 메모리에서 읽어서 캐시에 저장 후 반환
    - Write-allocate / No write-allocate: 쓰기 시 캐시 미스 발생했을 때 캐시에 올릴지 말지 결정

9. Lock / 트랜잭션 / 데드락
    - Lock: 동시성 제어 도구, 한 번에 하나의 프로세스/스레드만 자원 접근 가능하게 잠금
    - 트랜잭션 (ACID): 데이터베이스에서 논리적인 작업 단위, 성공하면 커밋, 실패하면 롤백 → 원자성, 일관성, 격리성, 지속성 보장
    - 데드락 (Deadlock): 두 프로세스가 서로 자원을 점유하고, 서로 상대 자원을 기다리며 무한 대기 → 발생 조건: 상호 배제, 점유와 대기, 비선점, 순환 대기 → 예방: 자원 순서 지정, 타임아웃, 은행원 알고리즘 등

- FCFS / RR 스케줄링이란?
    - FCFS (First-Come First-Served)
        - 먼저 온 프로세스가 먼저 실행되는 방식
        - 가장 단순한 스케줄링 → 줄 선 순서대로 처리
        - 문제점: 첫 번째 프로세스가 오래 걸리면, 뒤에 있는 프로세스는 계속 기다려야 함 → Convoy 효과(호위 효과) 비선점형 스케줄링
    - RR (Round Robin)
        - 일정 시간 단위(타임 퀀텀)를 정해서, 각 프로세스에게 번갈아가며 CPU를 할당
        - 시간 다 되면 선점하고, 다음 프로세스로 넘어감
        - 모든 프로세스가 공평하게 실행, 선점형 스케줄링 대표
        - 단점: 타임 퀀텀이 너무 작으면 컨텍스트 스위칭 비용 커짐 / 너무 크면 FCFS처럼 됨

- 내부 단편화 / 외부 단편화
    - 내부 단편화 (Internal Fragmentation): 할당받은 메모리 블록 안에 남은 낭비 공간
        - 예: 10KB 메모리 요청 → 12KB 고정 크기 블록 할당 → 2KB 낭비
        - 고정 크기 블록 할당 시 주로 발생
    - 외부 단편화 (External Fragmentation)
        - 메모리 전체에는 빈 공간이 충분한데, 연속된 큰 공간이 없어서 할당이 안 되는 경우
        - 예: 메모리에 1KB, 2KB, 3KB 빈틈이 흩어져 있지만 5KB 연속 공간이 없음
        - 가변 크기 블록 할당 시 발생
    - 해결 방법
        - 페이징: 외부 단편화 해결 (고정 크기 블록 사용)
        - 세그멘테이션: 내부 단편화 줄이지만 외부 단편화 생길 수 있음
        - 압축(compaction): 외부 단편화 공간을 뭉쳐서 사용 (하지만 오버헤드 큼)


- Checksum이란?
    - 데이터 전송 중 오류를 감지하기 위한 값
    - 전송 전에 데이터를 일정한 방식으로 계산해서 "검사값(Checksum)"을 붙임
    - 수신 측도 똑같이 계산해서 원본과 같은지 비교 -> 같으면 정상, 다르면 오류 감지
    - UDP/TCP 패킷에 포함, 네트워크에서 데이터 손상 여부 확인, 파일 다운로드 무결성 확인(MD5, SHA 해시처럼) 등에 사용


- ACK (Acknowledge): "응답, 확인"을 의미하는 메시지
    - TCP 통신에서 수신자가 데이터 잘 받았다고 응답 신호(확인 응답) 보내는 것
    - 송신자는 ACK 받으면 "데이터 전송 완료!"로 인식
    - ACK 없으면 재전송

- NAK (Negative Acknowledge)
    - 수신자가 데이터가 잘못됐다고 알리는 신호
    - 오류가 있거나 못 받았을 경우, "다시 보내줘!"라고 하는 것
    - TCP는 보통 ACK만 사용하고, 타임아웃으로 재전송 처리
    - NAK는 오래된 프로토콜이나 저수준 통신에서 사용됨

- TCP 3-way handshake: SYN → SYN-ACK → ACK, 패킷 전송/응답 확인 등에 사용
    - 프로토콜 통신에서 "상태 확인" 기본 구조

- 페이지 교체 알고리즘이란?
    - 가상 메모리는 디스크 공간 일부를 메모리처럼 쓰는 기술
    - 프로세스가 필요한 페이지(Page)를 메모리에 불러오는데,
    - 메모리 공간(프레임 수)은 제한적이니까 더 이상 빈 공간이 없을 때 기존 페이지를 내쫓고 새로운 페이지를 넣어야 함!
    - 이걸 페이지 교체(Page Replacement)라고 해.

- 페이지 교체 알고리즘의 목적
    - 어떤 페이지를 쫓아내야 효율이 좋은가?
    - 최소한의 페이지 폴트(페이지 부재)가 발생하도록 선택하는 것!
    - 즉, 페이지를 교체할 때 뭘 버릴지 똑똑하게 결정하는 규칙이 페이지 교체 알고리즘!

- 대표적인 페이지 교체 알고리즘 2가지
    - FIFO (First-In, First-Out): 가장 먼저 메모리에 올라온 페이지를 먼저 내쫓는다.
        - 단순하지만 성능이 별로 좋지 않다 (벨라디의 이상 현상 발생 가능성)
    - LRU (Least Recently Used): 가장 오랫동안 사용되지 않은 페이지를 교체
        - 과거에 안 쓰였으니 앞으로도 덜 쓸 거라는 가정
        - 실제 시스템에서 가장 널리 사용되는 방법 중 하나!
    - OPT(Optimal Replacement): 앞으로 가장 오래 안 쓸 페이지를 교체 → 이론상 최적이지만 실제 구현 불가능 (미래를 모르니까!)
    - LFU (Least Frequently Used): 사용 횟수가 가장 적은 페이지를 교체

- TCP 3-way 핸드셰이크 과정 

- 클라이언트 → 서버 : SYN
    - 클라이언트가 서버에 연결 요청을 보냄

- 서버 → 클라이언트 : SYN + ACK
    - 서버가 클라이언트의 요청을 수락하고, 자기 쪽도 준비됐다고 응답
    - (SYN = 나도 연결 준비 완료 / ACK = 네 요청 잘 받음)

- 클라이언트 → 서버 : ACK
    - 클라이언트가 서버의 응답을 확인하고 최종적으로 응답

- 왜 3번이 필요한가?
    - 양쪽 모두 연결 상태가 "정상"이라는 걸 확인하기 위해서
    - 한쪽이 준비됐다고 하는 것만으로는 부족! => 클라이언트와 서버 양측 모두 수신과 송신 상태가 문제없음을 검증해야 함

- 반대로 커넥션을 끊을 때는 4-way 라고 함.


- 더티 리드 (Dirty Read)
    - 다른 트랜잭션이 커밋하지 않은 데이터를 읽는 현상
    - 나중에 그 트랜잭션이 롤백되면 잘못된 데이터를 읽은 게 됨
    - 발생하는 수준: Read Uncommitted

- 논리피터블 리드 (Non-Repeatable Read)
    - 같은 데이터를 두 번 읽었는데 값이 달라지는 현상
    - 중간에 다른 트랜잭션이 해당 데이터를 수정하고 커밋한 경우
    - 발생하는 수준: Read Committed

- 팬텀 리드 (Phantom Read)
    - 같은 조건의 쿼리를 반복 수행했는데, 조건에 부합하는 레코드 개수가 달라지는 현상
    - 중간에 다른 트랜잭션이 새로운 레코드를 삽입하거나 삭제한 경우
    - 발생하는 수준: Repeatable Read(방지 X) → Serializable에서만 방지 가능!

- 동시성 성능 관점에서
    - Read Uncommitted가 가장 빠름
    - Serializable은 가장 느리고 락이 많음

- 일관성 관점에서
    - Serializable이 가장 강력한 일관성 보장
    - 낮은 격리 수준은 동시성은 좋지만 일관성은 약함

- 시간 지역성 (Temporal Locality)
    - 최근에 접근한 데이터는 가까운 미래에 다시 접근될 가능성이 높다!
    - 메모리에서 자주 쓰는 데이터를 캐시에 저장하면 빠르게 접근 가능
    - 예시: 반복문에서 사용하는 변수 → for (int i=0; i<1000; i++) → i 값이 계속 접근됨, 함수에서 자주 호출되는 데이터 → 같은 값 계속 쓰니까 캐시 히트율이 높아짐

- 공간 지역성 (Spatial Locality)
    - 현재 접근 중인 메모리 주소 근처의 데이터도 곧 접근할 가능성이 높다!
    - 그래서 캐시는 데이터를 한 번에 블록 단위로 가져옴
    - 예시: 배열 순차 접근 → arr[0], arr[1], arr[2]... 처럼 순서대로 접근할 때 → 한 번에 블록으로 가져와서 빠르게 처리 가능, 연속된 명령어 실행 → 프로그램이 순차적으로 명령어를 실행할 때 근처 명령어가 자주 실행됨

- 로컬리티
    - 캐시 메모리 설계는 이 두 가지 지역성을 최대한 활용해서 성능을 최적화한다!
    - 페이지 교체 알고리즘도 LRU 등 시간 지역성을 고려해서 만들어졌다!


- HTTPS 과정 흐름 (알기 쉽게 설명)
    - 클라이언트(브라우저)가 서버에 접속 시도
    - 서버가 자기 신원을 증명하는 인증서를 클라이언트에 보냄
        - 여기에 서버의 **공개키(Public Key)**도 들어있어
    - 클라이언트가 인증서를 검증하고,
        - **대칭키(세션키)**를 하나 만들어!
        - 이걸 서버의 공개키로 암호화해서 서버한테 보냄
    - 서버는 자신의 **개인키(Private Key)**로 복호화해서 대칭키를 얻음
    - 이후엔 서버와 클라이언트가 같은 대칭키로 통신 시작!
    - 데이터는 빠르고 안전하게 암호화됨 (대칭키는 빠르니까)


- L4 로드밸런서
    - 전송 계층 (Layer 4)에서 동작
    - 클라이언트와 서버의 IP 주소, 포트 번호 기준으로 트래픽 분산
    - TCP/UDP 트래픽을 빠르게 전달 (패킷 레벨에서 처리)
    - 속도가 빠르고, 주로 내부 네트워크 라우팅에서 사용됨
    - 예시: AWS NLB(Network Load Balancer), 일반 하드웨어 로드밸런서

- L7 로드밸런서
    - 애플리케이션 계층 (Layer 7)에서 동작
    - HTTP/HTTPS 트래픽을 요청 URL, 헤더, 쿠키 등 컨텐츠 기반으로 분석하고 분산
    - 사용자가 요청한 서비스나 기능에 따라 라우팅 가능
    - 카나리 배포, A/B 테스트, 사용자 기반 라우팅, 웹 방화벽(WAF) 기능 지원
    - 예시: AWS ALB(Application Load Balancer), NGINX, Envoy


- 로드밸런싱
    - 기본은 L4로 IP와 포트 기반 트래픽 분산
    - L7 로드밸런서로 컨텐츠 기반 분산 가능 (예: 이미지 서버/텍스트 서버 분리)
    - 오토스케일링 연동
        - 서버가 과부하면 인스턴스를 자동으로 증가시키고, 줄일 땐 줄이는 구조
        - 전용 이미지 서버 따로 배포
        - 이미지나 동영상은 CDN과 연동해서 별도 분산 필요

- 캐싱 전략
    - 클라이언트 캐싱: 브라우저 캐시 (HTTP 캐시 헤더 사용: Cache-Control, ETag)
    - 서버 캐싱 (애플리케이션 캐시); Redis, Memcached 사용
    - 조회수가 많은 게시글, HOT 데이터 캐싱 → DB 부하 감소

- CDN (Content Delivery Network): 전 세계 엣지 서버에 이미지, 정적 리소스를 캐싱
    - 클라우드플레어, AWS CloudFront, Naver CDN 등이 예시

- Cache Invalidation
    - 데이터가 변경될 때 캐시 삭제 전략 필요 (TTL, LRU 등)

- 추가적으로 고려할 설계 포인트
    - DB Replication; 읽기 전용 트래픽은 Read Replica로 분산
    - Write 집중 서버 분리: 쓰기와 읽기를 분리한 데이터베이스 아키텍처 (마스터-슬레이브 구조)

- 모범 답안 예시 (시험/면접용)
    - 트래픽이 많아지면 기본적으로 로드밸런서를 통해 서버 간 부하를 분산시켜야 한다.
        - L4 로드밸런서로 IP/Port 기반 분산
        - L7 로드밸런서로 HTTP 요청 경로에 따라 서버 분기
    - 캐싱은 데이터베이스 부하 감소와 응답 시간 개선에 필수적이다.
        - Redis/Memcached를 통해 HOT 데이터를 캐싱하고
        - CDN을 활용해 정적 파일(이미지, 동영상)을 엣지 서버에 저장하여 빠르게 제공
        - 오토스케일링, DB Read Replica, 캐시 무효화 정책도 함께 설계하여 트래픽 폭주에 대응할 수 있다.

- 프로세스 스케줄링
    - FCFS (First Come, First Served): 비선점형, 선입선출 방식
    - RR (Round Robin): 선점형, 타임 퀀텀 기반, 공평한 시간 할당
    - SRTF (Shortest Remaining Time First): 선점형 SJF, 남은 시간 기준으로 우선순위 결정
    - SJF + Exponential Averaging / HRRN: 과거 패턴 기반 CPU 사용 시간 예측하여 스케줄링

- SJF는 구현이 어렵다
    - 이유: 프로세스의 정확한 실행 시간을 사전에 알 수 없음
    - 그래서 과거 실행 시간을 기반으로 예측 (Exponential Averaging) => 이를 통해 SJF를 근사 구현할 수 있음!



