## Network

### **1. 데이터 엔지니어링에서 OSI & TCP/IP 모델**

- 분산 ETL 작업이 원격 PostgreSQL 데이터베이스에서 데이터를 가져올 때 **OSI 모델**은 어떻게 적용되며, 어떤 계층이 관련될까?
    - **애플리케이션 계층 (Layer 7):** ETL 도구는 PostgreSQL 프로토콜을 사용하여 TCP/IP를 통해 통신.
    - **전송 계층 (Layer 4):** TCP는 ETL 작업과 PostgreSQL 간 신뢰할 수 있는 데이터 전송을 보장.
    - **네트워크 계층 (Layer 3):** IP가 패킷을 네트워크를 통해 라우팅.
    - **데이터 링크 & 물리 계층 (Layers 2 & 1):** 이더넷, Wi-Fi 또는 기타 물리적 연결이 데이터 패킷을 전송.
- SFTP 서버에서 데이터 웨어하우스로 데이터를 수집하는 **데이터 파이프라인**을 설계할 때, 가장 관련된 프로토콜과 OSI 계층은?
    - **애플리케이션 계층 (Layer 7):** SFTP 프로토콜을 사용하여 보안 파일 전송 수행.
    - **전송 계층 (Layer 4):** TCP가 패킷의 순서 및 신뢰성을 보장.
    - **네트워크 계층 (Layer 3):** IP가 패킷을 목적지까지 전달.
    - **데이터 링크 계층 (Layer 2):** 이더넷/Wi-Fi가 물리적 주소 지정 관리.
- 여러 **데이터 센터 간 대용량 데이터 전송이 필요한 분산 ETL 파이프라인**을 설계할 때, **OSI 및 TCP/IP 모델을 고려하여** 어떻게 패킷 손실과 지연 시간을 최소화할 수 있을까?
    - **압축 활용**하여 페이로드 크기 축소.
        - **애플리케이션 수준 압축:** Spark에서 Parquet 또는 ORC 포맷 사용. → columnar
        - **네트워크 수준 압축:** TCP/TLS 압축 활성화. → 폐쇄적인 네트워크에서만 사용하고, 그렇지 않으면 비활성 권장(세션 쿠키 가로챌 수 있음)
        - **프로토콜별 압축:** Kafka의 Snappy 압축, gRPC의 Protobuf 내장 압축 사용.
    - **TCP 윈도우 스케일링 최적화**하여 처리량 향상. → ACK 까지의 65535바이트의 제한을 늘림
        - **수신 윈도우(Receive Window) 크기**가 작으면 고 지연 네트워크에서 병목 발생. → 수신측이 ACK를 더 자주 기다려야함.
        - 윈도우 스케일링을 통해 최대 **1GB**까지 확장 가능.
    - **부하 분산 및 CDN 활용**하여 네트워크 트래픽 분산.
        - Kafka 클러스터 간 **MirrorMaker**를 사용하여 **크로스 리전 복제**. → 작업 오버헤드?
        - CloudFront, AWS S3 캐싱을 활용하여 응답 속도 최적화. cloudfront는 cdn. S3는 좀더 중앙화
    - **병렬 처리 및 파티셔닝**을 통해 데이터 스트림을 작은 청크로 분할.
- **실시간 데이터 수집 시스템**에서 TCP와 UDP 중 무엇을 선택할까?
    - **TCP:** 신뢰성과 패킷 순서 보장이 필요한 경우 (예: 금융 거래).
    - **UDP:** 초저지연 처리가 중요한 경우 (예: 주식 시장 실시간 가격 데이터).

---

### **2. 데이터 전송에서 네트워크 패킷 & 헤더**

- **API를 통한 대용량 데이터 전송** 시 TCP 패킷 단편화(Fragmentation)가 성능에 미치는 영향과 최적화 방법?
    - **MTU 튜닝** 및 **청크 전송 인코딩(Chunked Transfer Encoding)** 활용.
    - **Keep-Alive 및 지속적 연결(Persistent Connection)** 사용하여 재전송 최소화.
- **원격 Kafka 프로듀서에서 JSON 페이로드 손상이 자주 발생**할 경우, 어떤 네트워크 레벨 헤더를 확인할까?
    - **IP 헤더:** 패킷 단편화(Fragmentation) 문제 확인.
    - **TCP 체크섬(Checksum):** 데이터 무결성 검증.
    - **Kafka 메시지 헤더:** 인코딩 오류 분석.
- **실시간 데이터 스트리밍 작업**에서 예상치 못한 패킷 손실 및 메시지 불일치가 발생할 때, **Wireshark/TCPDump**를 활용한 진단 방법?
    - **TCP 재전송 및 패킷 손실 분석**.
    - **네트워크 혼잡(Network Congestion) 및 버퍼 오버플로우 모니터링**.
    - **소켓 버퍼 크기 조정**.

---

### **3. ETL 파이프라인에서 네트워크 병목**

- 클라우드 기반 데이터 레이크에서 **ETL 작업 속도가 예상보다 느릴 때**, 네트워크 병목 원인과 해결 방법?
    - **MTU 크기 불일치로 인한 패킷 단편화 발생**.
    - **TCP 혼잡 제어 알고리즘(Reno/Cubic vs. BBR) 최적화**.
    - **네트워크 지연 및 대역폭 한계 확인**.
    - **CDN 및 엣지 컴퓨팅 활용하여 트래픽 분산**.

---

### **4. 데이터 이동에서 캡슐화(Encapsulation) & 디캡슐화(Decapsulation)**

- **Kafka를 통한 대용량 데이터 전송** 시 캡슐화 과정과 관련된 헤더?
    - **Kafka 메시지 → TCP/IP → 이더넷 헤더** 추가 후 네트워크 전송.
- **Spark가 S3에서 데이터를 읽을 때** 네트워크 계층에서의 데이터 처리 방식?
    - **HTTP 계층:** 요청 처리.
    - **전송 계층:** 신뢰성 있는 데이터 스트리밍 보장.
    - **데이터 링크 및 물리 계층:** 데이터 전송 수행.
- **Kubernetes 클러스터 내 마이크로서비스 간 데이터 이동** 시 캡슐화 영향?
    - **HTTP/gRPC over TCP** 통신 사용.
    - **서비스 메쉬(Istio/Linkerd) 활용**하여 트래픽 관리.

---

### **5. 네트워크 토폴로지 & 데이터 파이프라인**

- 다중 데이터 센터에서 **효율적인 데이터 복제를 위한 네트워크 토폴로지** 선택?
    - **스타(Star) 토폴로지:** 중앙 집중식, 병목 위험 존재.
    - **메시(Mesh) 토폴로지:** 높은 장애 허용성 제공.
    - **하이브리드(Hybrid) 토폴로지:** 효율성과 중복성을 균형 있게 유지.

---

### **6. 이더넷 & 패킷 전송**

- **IoT 센서 데이터를 스트리밍**할 때 **Ethernet MTU 설정이 성능에 미치는 영향**?
    - **MTU 크기 증가**는 오버헤드를 줄이지만, 네트워크 단편화 발생 가능.
    - 고성능 네트워크에서는 **점보 프레임(Jumbo Frames)** 사용 고려.

---

### **7. 프로토콜 선택 & 데이터 엔지니어링**

- **REST API 속도가 느릴 때** HTTP/1.1 → HTTP/2/gRPC로 변경하면 어떤 성능 이점이 있을까?
    - **HTTP/2:** 멀티플렉싱 지원, 지연 시간 감소.
    - **gRPC:** Protobuf 기반으로 페이로드 크기 최소화.
- **고빈도 실시간 데이터 수집(예: 주식 시장 데이터)** 시 UDP vs TCP 선택 기준?
    - **UDP:** 초저지연 처리 가능 (패킷 손실 감수).
    - **TCP:** 신뢰성과 순서 보장이 필요할 때.

---

### **8. 데이터 엔지니어링에서의 전송 방식 및 부하 분산**

- 여러 개의 다운스트림 소비자에게 데이터를 스트리밍할 때, **유니캐스트, 멀티캐스트, 브로드캐스트 각각 어떻게 사용하나**?
    - **유니캐스트 (Unicast):** 일대일 통신 (예: 클라이언트-서버 쿼리).
    - **멀티캐스트 (Multicast):** 일대다 통신 (예: 실시간 분석 데이터 스트리밍).
    - **브로드캐스트 (Broadcast):** 작은 네트워크 내에서 전체 노드로 데이터 전송.
- 클라우드 기반 Apache Kafka 소비자 그룹의 부하를 효과적으로 분산하려면 어떻게 해야 할까요?
    - **파티셔닝된 소비**: 여러 소비자가 서로 다른 파티션을 처리하도록 분배.
    - **고정 소비자 (Sticky consumers)**: 순서가 중요한 데이터를 올바르게 처리하도록 유지.

---

### **9. 데이터 API 엔드포인트에서 HTTP vs. gRPC**

- 데이터 수집 API를 개발할 때, 성능, 페이로드 크기, 프로토콜 오버헤드를 고려하여 **HTTP/REST**와 **gRPC over TCP** 중 어떤 것을 선택해야 할까요?
    - **REST:** 호환성이 뛰어나지만 속도가 상대적으로 느림.
    - **gRPC:** 성능이 뛰어나고 오버헤드가 낮아 마이크로서비스 간 통신에 적합. → 브라우저 x

---

### **10. 데이터 파이프라인의 네트워크 장애 처리**

- 원격 API에서 매시간 데이터를 추출하는 배치 작업이 실행되지만, 네트워크 장애로 인해 불완전한 데이터셋이 발생하는 경우가 있습니다. 이를 효과적으로 처리하려면 어떤 전략을 사용해야 할까요?
    - **백오프(Exponential Backoff)를 적용한 재시도 메커니즘** 구현. 네트워크 오류나 충돌이 발생했을 때, 재시도 간격을 점진적으로 늘려가며 재시도
    - 멱등성(Idempotency)을 보장하여 동일한 요청이 여러 번 실행되어도 일관된 결과 유지.

---

### **11. 로드밸런서와 데이터 엔지니어링 API**

- 다수의 클라이언트가 데이터를 요청하는 **고부하 API**에서 부하 분산기는 어떻게 성능을 향상시키며, 스티키 세션(Sticky Session)과 무상태 요청(Stateless Request)을 처리할 때 어떤 고려 사항이 필요할까요?
    - **라운드 로빈(Round-robin), 최소 연결(Least connections) 알고리즘**을 활용하여 무상태 요청을 효율적으로 분산.
    - 상태 유지가 필요한 트랜잭션의 경우 **스티키 세션**을 사용하여 특정 클라이언트 요청을 동일한 서버로 라우팅.

---

### **12. 엣지 컴퓨팅(Edge Computing)과 데이터 엔지니어링**

- IoT 데이터 파이프라인에서 센서 장치가 클라우드 기반 데이터 웨어하우스로 데이터를 전송할 때, **엣지 컴퓨팅**은 네트워크 혼잡을 어떻게 줄이고, 어떤 프로토콜(MQTT, WebSockets 등)을 사용해야 할까요?
    - **엣지에서 데이터를 사전 처리**하여 네트워크 트래픽 감소.
    - 실시간 업데이트가 필요할 경우 **MQTT/WebSockets** 활용.

---

### **13. 네트워크 토폴로지와 데이터 흐름 최적화**

- 다중 지역에서 고객 거래 데이터를 처리하는 데이터 파이프라인을 구축할 때, 네트워크 토폴로지(예: 메시, 스타, 하이브리드)가 데이터 아키텍처의 효율성과 내결함성(Fault Tolerance)에 미치는 영향은 무엇인가요?
    - **메시 토폴로지 (Mesh Topology):** 다중 경로를 제공하여 장애에 대한 복원력이 높음.
    - **스타 토폴로지 (Star Topology):** 중앙 집중식 관리가 가능하지만 중앙 노드에 장애가 발생하면 전체 네트워크에 영향.

---

### **14. CDN과 데이터 웨어하우징 성능 최적화**

- 데이터 엔지니어링 팀이 **전 세계 사용자**에게 **사전 집계된 분석 데이터**를 제공해야 합니다. CDN이 네트워크 지연을 줄이는 데 어떻게 기여할 수 있으며, 어떤 캐싱 메커니즘을 구현할 수 있을까요?
    - **사전 집계된 데이터(Pre-aggregated data)를 캐시**하여 처리 속도를 향상.
    - 지역별 엣지 서버(Regional Edge Servers)를 활용하여 사용자와 가까운 곳에서 데이터 제공.

---

## Study Week 1

### 1-1 사용자가 API에 요청을 해서 응답을 받기까지의 과정을 데이터 계층 모델로 묘사해보시유?

🔎 **1. 응용 계층 (Application Layer - HTTP / REST API / JSON)**

- **무슨 일이 일어나나요?**
    
    클라이언트(브라우저, Postman, curl 등)가 HTTP 요청을 생성합니다.
    
    예시:
    
    `GET /api/data HTTP/1.1`
    
- 헤더, 인증 토큰 등이 포함됩니다.
- **전송할 데이터 형식:** JSON (`Content-Type: application/json`)
- **역할:** 사용자 데이터(요청)를 전송하고 응답을 받는 최상위 계층

➡️ 작성된 요청은 아래 전송 계층으로 전달됩니다.

---

🔎 **2. 전송 계층 (Transport Layer - TCP)**

- **무슨 일이 일어나나요?**
    - HTTP 요청을 **TCP 세그먼트**로 나누고, 신뢰성 있게 전송
    - 연결 과정: **3-way 핸드셰이크 (SYN → SYN-ACK → ACK)**
    - 순서 보장, 패킷 재전송 처리
- **포트 번호:** 서버는 보통 **80(HTTP)** 또는 **443(HTTPS)** 포트로 대기
- **역할:** 데이터가 빠짐없이 순서대로 도착하도록 보장

---

🔎 **3. 네트워크 계층 (Network Layer - IP)**

- **무슨 일이 일어나나요?**
    - TCP 세그먼트를 **IP 패킷**으로 감싸고,
    - **출발지 IP**(내 컴퓨터), **목적지 IP**(API 서버) 부여
- **라우팅:** 여러 라우터를 거쳐 목적지로 이동 (경로 결정)
- **주의:** 패킷 크기 초과 시 분할 (Fragmentation), TTL 감소

---

🔎 **4. 데이터 링크 계층 (Data Link Layer - 이더넷 / Wi-Fi / 5G)**

- **무슨 일이 일어나나요?**
    - IP 패킷을 프레임으로 감싸 전송 준비
        - 유선이면 Ethernet Frame
        - 무선이면 Wi-Fi Frame
        - 모바일이면 5G/LTE 프레임
    - **MAC 주소**를 사용해 같은 네트워크 내 장치로 전달
    - **ARP 프로토콜:** IP를 MAC 주소로 변환해줌

---

🔎 **5. 물리 계층 (Physical Layer - 전선 / 광섬유 / 무선 신호)**

- **무슨 일이 일어나나요?**
    - 0과 1로 이루어진 비트가 **전기 신호 / 빛 신호 / 전파**로 변환되어 전송
    - 예시:
        - 랜선 → 전기 신호
        - 광케이블 → 빛 신호
        - Wi-Fi / 5G → 무선 전파
- **역할:** 실제 데이터를 물리적으로 이동시키는 구간

---

🔄 **서버 응답 과정도 동일하게 반대 방향으로 진행**

- 서버가 요청을 받아 처리하고 **JSON 데이터를 포함한 HTTP 응답**을 생성
- 응답 데이터가 다시 **물리 계층 → 데이터 링크 → 네트워크 → 전송 → 응용 계층** 순으로 올라오고
- 최종적으로 클라이언트가 **JSON 데이터 파싱 및 처리**

### 1-2. 대용량 데이터를 수집힐 때, 전송, 네트워크 계층에서 어떤 문제가 발생할 수 있을까요?

**전송 계층 문제 및 해결책**

**전송 계층 (Layer 4)** 은 종단 간(end-to-end) 통신, 오류 복구, 혼잡 제어를 담당합니다.

**1. 높은 지연 시간(Latency) & 패킷 손실(Packet Loss)**

- **문제:** 대용량 데이터 전송 시 네트워크 혼잡으로 인해 패킷 손실 및 재전송이 발생할 수 있음.
- **해결책:**
    - **Multipath TCP (MPTCP)** 를 사용하여 여러 네트워크 경로로 트래픽을 분산.
    - **QUIC (Quick UDP Internet Connections)** 을 활용하여 저지연 데이터 전송 수행.
    - **최적화된 혼잡 제어 알고리즘** (예: Reno/Cubic 대신 BBR) 적용.

---

**2. TCP 처리량(Throughput) 병목**

- **문제:** TCP의 혼잡 제어로 인해 대규모 데이터 스트림 처리 시 처리량이 제한될 수 있음.
- **해결책:**
    - **UDP 기반 전송** (예: QUIC, RDMA over Converged Ethernet) 활용.
    - TCP 윈도우 크기 및 버퍼 크기 최적화.
    - **병렬 TCP 스트림(Parallel TCP Streams)** 을 사용하여 대역폭 극대화.

---

**3. 비효율적인 데이터 직렬화(Serialization)**

- **문제:** JSON과 같은 비효율적인 직렬화 형식 사용 시 전송 성능 저하 가능.
- **해결책:**
    - **Apache Avro, Protocol Buffers, FlatBuffers** 와 같은 **바이너리 포맷(Binary Format)** 사용.
    - 데이터 전송 전에 **Snappy, LZ4** 등의 알고리즘으로 압축.

---

**4. 내결함성(Fault Tolerance) 및 데이터 무결성(Data Integrity)**

- **문제:** 데이터 전송 중 일부 패킷이 손상되거나 누락될 가능성이 있음.
- **해결책:**
    - **체크섬(Checksum) 기반 검증** (예: TCP 체크섬, CRC) 적용.
    - 애플리케이션 레벨에서 **재시도(Retry) 및 중복 제거(Deduplication) 메커니즘** 구현.

---

**네트워크 계층 문제 및 해결책**

**네트워크 계층 (Layer 3)** 은 패킷 전달(Forwarding), 라우팅(Routing), 주소 지정(Addressing)을 담당합니다.

**1. 대역폭(Bandwidth) 제한**

- **문제:** 제한된 대역폭으로 인해 대용량 데이터 전송 속도가 느려질 수 있음.
- **해결책:**
    - 전송 전 **데이터 압축(Data Compression)** 적용.
    - 여러 경로에 걸쳐 **라우팅 최적화 및 부하 분산(Load Balancing)** 수행.
    - **CDN (Content Delivery Network)** 을 활용하여 트래픽을 효율적으로 분산.

---

**2. 네트워크 혼잡(Network Congestion) & 패킷 순서 변경(Packet Reordering)**

- **문제:** 대규모 데이터 전송 시 네트워크가 혼잡해져 패킷 지연 또는 순서 변경 발생 가능.
- **해결책:**
    - **QoS (Quality of Service) 정책** 을 적용하여 중요한 데이터 우선 처리.
    - TCP/IP 스택에서 **ECN (Explicit Congestion Notification)** 활성화.
    - **SDN (Software-Defined Networking)** 을 활용하여 동적 라우팅 최적화.

---

**3. IP 단편화(Fragmentation) 문제**

- **문제:** 대형 패킷이 단편화되면 재조립 과정에서 성능 저하 발생 가능.
- **해결책:**
    - **MTU (Maximum Transmission Unit)** 값을 조정하여 단편화를 방지.
    - 고성능 네트워크 환경에서 **Jumbo Frames** (9,000바이트) 사용.

---

**4. 비효율적인 라우팅(Routing) & 장애(Failure)**

- **문제:** 잘못된 라우팅 결정 또는 장애로 인해 지연 시간이 증가할 수 있음.
- **해결책:**
    - 데이터 센터 간 전송을 최적화하기 위해 **BGP (Border Gateway Protocol) 최적화** 수행.
    - **애니캐스트(Anycast) 라우팅** 을 활용하여 데이터 전송 거리를 단축.

---

### 1-3. 패킷 로스를 방지하기 위해서 ? (1-2랑 같은듯)

- 요청 청킹

✅ **1. 압축(Compression)으로 페이로드 크기 감소**

- **애플리케이션 레벨 압축**: 데이터 파일을 압축된 포맷으로 저장 (예: Spark에서 Parquet 또는 ORC 포맷 사용)
- **네트워크 레벨 압축**: TCP 전송 시 압축 적용 가능 (예: HTTPS에서 TLS 압축)
- **프로토콜 별 압축**: Kafka의 Snappy 압축, gRPC의 Protobuf 내장 압축 등

---

✅ **2. TCP 윈도우 스케일링(Window Scaling) 최적화**

- TCP **윈도우 스케일링**은 고속 및 고지연 네트워크 환경에서 수신 윈도우 크기를 기본값(65,535 바이트)보다 크게 확장해 전송 효율을 높이는 기능입니다.
- *수신 윈도우(Receive Window)**란, 수신 측에서 ACK 없이 한 번에 수신 가능한 데이터의 양을 의미합니다.
- 데이터 센터 간 전송처럼 지연이 큰 네트워크에서는 윈도우 크기가 작으면 **처리량(Throughput) 병목**이 발생할 수 있습니다.
- TCP 윈도우 스케일링을 적용하면 **최대 1GB까지 윈도우 확장**이 가능해져 ACK를 기다리지 않고 더 많은 데이터를 전송할 수 있습니다.

---

✅ **3. 로드 밸런싱 및 CDN 활용으로 트래픽 분산**

- Kafka는 파티션을 통해 기본적으로 분산 처리하지만, 추가적으로 **라운드 로빈(Round Robin), 최소 연결(Least Connections)** 등의 전략을 고려할 수 있습니다.
- *CDN(Content Delivery Network)**은 대규모 데이터셋(예: 사전 집계된 분석 결과)을 제공하는 ETL 파이프라인에서 유용합니다.

📌 **예시 1: Cloudflare 또는 AWS CloudFront 활용 (캐시 데이터 제공)**

- ETL 작업이 생성한 결과물을 **S3**에 저장하고, **CloudFront**로 캐싱하여 원본 서버의 부하를 줄일 수 있습니다.
- CloudFront가 데이터를 캐싱하므로 데이터 전송 비용 절감 및 사용자별 **가장 가까운 엣지 서버에서 데이터 제공**이 가능합니다.

📌 **예시 2: Kafka MirrorMaker를 통한 데이터 센터 간 복제**

- 두 개 이상의 데이터 센터에 Kafka 클러스터가 있는 경우, **Kafka MirrorMaker**를 사용해 토픽을 지역 간 복제할 수 있습니다.
- 클라이언트는 **가장 가까운 클러스터에서 소비(Consume)** 하여 지연을 줄일 수 있습니다.

---

✅ **4. 병렬 처리(Parallelism) 및 파티셔닝(Partitioning) 활용**

- 데이터를 적절한 크기의 조각으로 나누어 병렬로 처리함으로써 대용량 전송을 효율화할 수 있습니다.

---

### 2-1**. 리버스 프록시(Reverse Proxy)는 무엇인가요? 일반 프록시와 어떤 차이가 있나요?**

**A.**

리버스 프록시는 클라이언트가 아닌 **서버 측**에 위치하는 프록시입니다. 클라이언트는 리버스 프록시를 통해서만 서버에 접근하고, 리버스 프록시가 여러 서버 중 적절한 서버로 요청을 전달합니다.

일반 프록시는 클라이언트가 목적지 서버에 접근하는 것을 대신하는 반면, 리버스 프록시는 서버가 클라이언트의 요청을 직접 받지 않고 리버스 프록시가 대신 받아 처리한다는 점이 가장 큰 차이입니다.

리버스 프록시는 주로 **로드 밸런싱, SSL 종료, 보안 강화, 캐싱** 등의 목적으로 사용됩니다.

### 2-2 **프록시나 리버스 프록시가 데이터 엔지니어링 환경에서 어떻게 사용될 수 있을까요?**

**A.**

데이터 엔지니어링 환경에서는 API 서버 앞단에 리버스 프록시를 두어 다음과 같은 용도로 사용할 수 있습니다:

- 데이터 수집 API의 부하 분산 (로드 밸런싱)
- 인증 및 접근 제어 강화
- 외부 API 호출 시 프록시 서버를 이용해 IP 우회 및 요청 로그 기록
- 캐싱을 통해 중복된 데이터 요청 방지 및 성능 최적화

예를 들어, Nginx나 Envoy 같은 리버스 프록시를 배치해 외부에서 들어오는 데이터 스트림을 분산 처리하고, 내부 데이터 파이프라인으로 전달할 수 있습니다.

### 2-3 **ETL 파이프라인에서 리버스 프록시를 사용하는 사례를 설명해보세요.**

**A.**

ETL 파이프라인에서 리버스 프록시는 주로 **데이터 수집(Extract) 단계**에서 사용됩니다.

예를 들어, 외부 파트너사나 IoT 기기에서 API를 통해 데이터가 들어오는 구조라면, 리버스 프록시(Nginx, Envoy 등)를 앞단에 두어:

- **트래픽 부하 분산**
- **SSL 처리 및 인증 수행**
- **요청 데이터 유효성 검사**
- **임시 캐싱 후 Batch성 처리**

같은 작업을 수행할 수 있습니다. 이렇게 하면 데이터 수집 서버의 부하를 줄이고, 데이터 유입 지점을 일원화해 관리와 모니터링이 쉬워집니다.

### 2-4 **데이터 엔지니어링에서 리버스 프록시를 이용해 트래픽을 어떻게 효율적으로 관리할 수 있을까요?**

**A.**

데이터 파이프라인의 API 수집 구간에 리버스 프록시를 두면:

- **Rate Limiting(속도 제한)** 기능으로 특정 클라이언트의 과도한 요청을 제어할 수 있습니다.
- **캐싱**을 통해 동일한 요청이 반복되는 경우, 백엔드 API 서버로의 호출을 줄여 효율적으로 트래픽을 관리할 수 있습니다.
- **로드 밸런싱** 기능으로 데이터를 수집하는 API 서버들의 부하를 분산시켜 시스템 안정성을 확보할 수 있습니다.

예를 들어, 대용량의 IoT 데이터가 실시간으로 들어오는 환경에서 이런 구조를 적용하면 파이프라인 장애를 예방할 수 있습니다.

### 2-5 트래픽 분산은 백엔드 관점과 하드웨어 관점에서 어떻게 할 수 있을까요?

(High connectivity와  관련)

1. 하드웨어: 리눅스의 경우 NIC