# CS 레포 정리

- `https://gyoogle.dev/blog/computer-science/computer-architecture/%EC%BB%B4%ED%93%A8%ED%84%B0%EC%9D%98%20%EA%B5%AC%EC%84%B1.html`
- 위 url 참고하여 정리

## 1. 알고리즘

- 알고리즘이 stable => 같은 정렬 기준에 대해서 이전 순서를 유지 / unstable => 유지 못함

1. Bubble Sort

- 인접한 두개의 원소를 비교하며 순회하고, 이를 다시 반복하면서 한 순회 당 하나씩 큰 것부터 위치를 결정하는 정렬
- 시간 복잡도 O(n^2) / 공간 복잡도 O(n)
- 간단하고 직관적, 알고리즘이 stable / 시간 복잡도는 비효율적, swap 이 다수 발생


2. Selection Sort

- 먼저 인덱스를 초기화한다. i + 1 부터 순회하며 해당 자리에 들어갈 값을 찾는다. (작은 것부터 순회한다면, 제일 작은 값을 찾는다) => 이를 저장해뒀다가 인덱스를 교환한다.
- 위를 리스트를 여러번 순회하며 한다.
- 시간복잡도 O(n^2) / 공간 복잡도 O(n)
- Bubble에 비해 비교는 거의 같지만 교환은 적다. (기억만 해둔다) / 시간 복잡도 비효율적이고 Unstable하다.

3. Insertion Sort

- 두번째 원소부터 시작하여 맨 앞의 원소만큼이 이미 정렬된 리스트임. => 두번째 리스트를 적당한 위치에 넣음 => 이후 하나씩 가져와서 정렬된 부분의 적당한 위치에 삽입하는 형식
- 시간복잡도 최악 혹은 평균 O(n^2), 최적(이미 정렬된 경우) O(n) / 공간 복잡도 O(n)
- 이미 정렬된 배열에 하나의 원소를 삽입하는 경우 O(n)
- 대부분이 정렬된 경우 매우 효율적, Stable한 알고리즘 / 최악의 경우(일반적 경우) 비효율적인 시간 복잡도

4. Quick Sort

- 분할 정복 정렬 알고리즘, pivot을 정하고 그를 기준으로 리스트를 쪼개고, 이를 재귀적으로 적용하여 정렬
- pivot은 보통 맨앞, 맨뒤, 중간 인덱스를 가진 값 정도가 되며 이를 기준으로 더 작고 큰 원소를 나누어 이 그룹을 다시 재귀적으로 정렬
- 최선의 경우 O(nlogn) / 최악의 경우 O(n^2) (이미 오름차순 혹은 내림차순 정렬되어 있는 경우, 즉 매 재귀에서 한 그룹이 비어버리는 경우) / 공간 O(n)
- 다른 O(nlogn) 정렬 알고리즘과 비교해도 가장 빠른 편이나, Unstable하며 이미 어느정도 정렬된 경우 느려진다.

5. Mergo Sort 

- stable하며 분할 정복 정렬 알고리즘, 요소를 정렬 없이 최대한 쪼개고 합치면서 정렬해나가는 방법
- 최악, 최선, 평균이 모두 O(nlogn) 이나 공간적으로 하나의 리스트만큼이 더필요
- Stable하면서 빠르고, Quick sort에 비해 임의 접근의 효율성이 보장되지 않는 링크드 리스트와 같은 정렬에 사용하면 좋다

6. Heap sort

- 완전 이진트리를 기반으로 한 heap 자료 구조를 사용하여 정렬 => 최대 힙을 구성하고 여기서 최대값을 pop, 이후 남은 요소들의 힙을 다시 최대 힙으로 만들며 정렬
- unstable 하고 최악, 최선, 평균 모두 O(nlogn)

7. Radix Sort

- comparison sort: 위에서 말한 원소들끼리 직접 대소 등을 비교하며 정렬하는 알고리즘 => 비교를 최소화하더라도 O(nlogn)이 한계
- radix sort: 비교 기반이 아닌, 정수의 자리수, 문자열 등을 다루는 정렬 알고리즘
- LSD, MSD: Least, Most Siginificant Digit => 큰 자리수 부터, 작은 자리수부터 비교
- 각 자리수의 정렬은 counting sort(정수 비교에 주로 활용, 각 digit의 출현 빈도를 세고 그를 기반으로 정렬된 리스트를 새로 생성)으로 이루어짐 (stable)
- 시간 복잡도 O(d * (n + k)): d 는 자리수, n은 데이터 개수, k는 자리값(10진법이면 10)
- 문자열, 정수 등을 정렬할 수 있으나 자리수가 없는 것은 정렬할 수 없다는 단점이 있음.

8. Counting Sort

- 시간 복잡도 O(n + k), 공간 복잡도 O(k) (k는 배열의 최대값)
- 장점은 시간 복잡도가 선형이나, 공간 복잡도가 꽤 크다는 단점도 존재

9. Binary Search

- 정렬된 상태에서, 탐색 구간을 매번 반으로 줄여나가며 탐색하는 방법

10. Hash Table

- k-v 쌍 형태로 데이터를 저장하는 자료 구조
- key가 들어오면 hash function에 의해 이를 숫자로 바꾸고 이를 배열의 인덱스로 하여 O(1) 임의 접근 구현
- hash collision: 다른 키가 같은 해시 값을 가지는 경우
    - chaining: 같은 인덱스에 리스트로 여러 값을 저장한다
    - open addressing: 비어 있는 인덱스를 찾는다 => 선형 탐색 등
- 검색, 삽입, 삭제 모두 평균 O(1), 충돌이 항상 나는 경우 O(N)

11. DFS & BFS

- 그래프 알고리즘, 코테 문제에 자주 활용
- DFS: 다음 브랜치로 가기 전 해당 브랜치를 끝까지 탐색하는 방법
    - 보통 스택, 재귀를 통해 구현, 모든 경로를 방문해야할 때 적합
    - 시간 복잡도: 인접 행렬에서 O(V^2) / 인접 리스트에서 O(V + E)
- BFS: 인접한 노드들을 모두 방문하고, 다시 그 노드들에서 인접한 노드들을 다시 방문
    - 보통 큐를 사용해 구현, 최소 비용이 모든 경로 탐색보다 우선일 때 적합
    - 시간 복잡도: 인접 행렬에서 O(V^2) / 인접 리스트에서 O(V + E)

12. 최장 증가 수열(Longest Increasing Sequence)

- `[ 7, 2, 3, 8, 4, 5 ]` → 해당 배열에서는 `[2, 3, 4, 5]`가 LIS로 답은 4
- 구현 방법, 시간복잡도
    - DP : O(N^2)
    - Lower Bound : O(NlogN)
- dp에서는 i번째 인덱스에 `list[:i]`의 LIS를 구하는 방식
- lower bound는 시간 복잡도가 주나, LIS의 길이만 구할 수 있는 방법. 
    - 매 번 수열의 값을 가져오고 부분 수열과 비슷한 리스트를 두고 들어온 값이 더 크다면 길이 1 추가, 더 작다면 작은 원소를 갱신

13. 최소 공통 조상(Lowest Common Ancestor)

- LCA: 트리에서 두 노드의 가장 가까운 공통 조상
- 방법 1. 부모를 저장하고 올라가기
    - 두 노드의 부모를 거슬러 올라가며 공통 조상 찾기
    - 시간 복잡도 O(N) => 느려서 실전에서는 잘 안 씀!
- 방법 2. Binary Lifting (DP 방식)
    - 2^i번째 부모를 미리 저장해두고 점프해서 올라가는 방식
    - 트리를 깊이별로 레벨 저장하고, 두 노드의 레벨을 맞춘 다음 => 동시에 2^i씩 위로 올라가며 최소 공통 조상을 찾는다.
    - 전처리 O(N log N) / 쿼리 당 O(log N)

14. 동적 계획법(Dynamic Programming)

- 작은 문제를 풀고 그 결과를 저장해서(메모이제이션) => 큰 문제를 효율적으로 해결하는 방법
- 점화식(recursive relation)으로 반복되는 반복되는 부분 문제(overlapping subproblems)를 한 번만 계산해서 재사용하는 방식!
- 사용하는 때: 부분 문제의 중복이 있으며, 최적 부분 구조(optimal substructure)를 가진다 => 작은 문제의 최적해가 큰 문제의 최적해가 된다!
- DP의 종류
    - Top-Down (재귀 + 메모이제이션): 함수를 재귀 호출하면서 값을 저장
    - Bottom-Up (반복문 + 테이블): 작은 문제부터 차근차근 계산하며 테이블 채움

15. 다익스트라(Dijkstra) 알고리즘

- DP를 활용한 최단 경로 탐색 알고리즘
- 구현 방법

```
1. 최단 거리 값은 무한대 값으로 초기화한다.

2. 시작 정점의 최단 거리는 0이다. 그리고 시작 정점을 방문 처리한다.

3. 시작 정점과 연결된 정점들의 최단 거리 값을 갱신한다.

4. 방문하지 않은 정점 중 최단 거리가 최소인 정점을 찾는다.

5. 찾은 정점을 방문 체크로 변경 후, 해당 정점과 연결된 방문하지 않은 정점의 최단 거리 값을 갱신한다.

6. 모든 정점을 방문할 때까지 4~5번을 반복한다.
```

- 인접 행렬 시간 복잡도는 O(N^2)이다.
- 인접 리스트 시간 복잡도는 O(NlogN)이다.
    - 선형 탐색으로 시간 초과가 나는 문제는 인접 리스트로 접근해야한다. (우선순위 큐)
- 간선의 값이 양수일 때만 가능하다.


16. 비트마스크(BitMask)

- 집합의 요소들의 구성 여부를 표현할 때 유용한 테크닉
- 아래와 같이 적용

```
[1,2,3,4,5] → 11111
[2,3,4,5]   → 11110
[1,2,5]     → 10011
[2]         → 00010
```

- 비트 연산
    - AND(&) : 대응하는 두 비트가 모두 1일 때, 1 반환
    - OR(|) : 대응하는 두 비트 중 모두 1이거나 하나라도 1일때, 1 반환
    - XOR(^) : 대응하는 두 비트가 서로 다를 때, 1 반환
    - NOT(~) : 비트 값 반전하여 반환
    - SHIFT(>>, <<) : 왼쪽 혹은 오른쪽으로 비트 옮겨 반환

