# 개념을 정말 간단히만 정리하기

## CS 요약 정리

#### 1. 운영체제 (OS)

- 프로세스 vs 스레드
    - 프로세스: 실행 중인 프로그램, 독립적인 메모리 공간.
    - 스레드: 프로세스 내에서 실행되는 작업 단위, 메모리 공간 공유.

- 멀티스레딩
    - 장점: 자원 공유로 메모리 절약, 응답성 향상.
    - 단점: 동기화 문제, 데드락 발생 가능. 

- 동기화 (Synchronization): 여러 스레드가 동시에 공유 자원(변수, 메모리)에 접근할 때 데이터의 일관성을 유지하기 위한 기술
    - 스레드들이 동시에 하나의 자원에 접근해서 값을 바꾸면 경쟁 조건(Race Condition)이 발생할 수 있음.
    - 락(Lock), 뮤텍스(Mutex), 세마포어(Semaphore) 같은 걸로 한 번에 하나의 스레드만 자원에 접근하도록 제어

- 데드락 (Deadlock): 두 개 이상의 스레드나 프로세스가 서로가 가진 자원을 기다리면서 무한 대기 상태에 빠지는 현상
    - 데드락 발생 조건 (4가지 전부 만족해야 함)
        - 상호 배제(Mutual Exclusion): 자원을 한 번에 하나의 스레드만 사용 가능
        - 점유와 대기(Hold and Wait): 자원을 가진 채로 다른 자원을 기다림
        - 비선점(No Preemption): 자원을 강제로 빼앗을 수 없음
        - 순환 대기(Circular Wait): 자원을 기다리는 순환 고리가 있음

- 락 (Lock): 공유 자원에 접근할 때 하나의 스레드만 접근 가능하게 잠그는 메커니즘
    - 임계 구역(Critical Section)에서 사용됨
    - 스레드가 락을 걸면 다른 스레드는 대기해야 함
    - 락을 해제하지 않으면 데드락 가능성 있음

- 뮤텍스 (Mutex): Mutual Exclusion(상호 배제)의 줄임말
    - 락과 비슷하지만 스레드 간에 소유권이 더 엄격해
    - 한 번에 하나의 스레드만 락을 얻을 수 있음
    - 해제는 락을 소유한 스레드만 가능
    - 프로세스 간 동기화도 가능 (락은 스레드 간 제한됨)

- 세마포어 (Semaphore): 카운터 기반 락
    - 특정 자원에 허용할 수 있는 동시 접근 수를 지정
    - 카운트가 0이 되면 대기 상태, 자원이 반납되면 카운트가 증가
    - Binary Semaphore → 0과 1만 가능 → 뮤텍스처럼 동작
    - Counting Semaphore → N개의 리소스를 관리할 때 사용


- 모니터 (Monitor): 락 + 조건 변수(Condition Variable)를 결합한 고급 구조
    - 스레드 간 락과 대기/알림을 효율적으로 관리
    - 락으로 보호되는 자원과 대기큐가 내부에 포함됨
    - Java의 synchronized나 Python의 threading.Condition()이 모니터 개념

- 문맥 교환(Context Switching)
    - CPU가 다른 프로세스로 전환될 때 발생. PCB 정보 저장/복구 필요.
    - 오버헤드 있음.

- PCB(Process Control Block): 프로세스의 상태를 저장하는 데이터 구조
    - 프로세스의 모든 정보를 담고 있는 데이터 블록
    - 운영체제가 각 프로세스를 관리하기 위해 반드시 필요해.
    - 프로세스 상태, 프로그램 카운터(PC), CPU 레지스터 값, 메모리 관리 정보, 프로세스 ID(PID), I/O 상태 정보 등 저장
    - 문맥 교환: CPU가 현재 실행 중인 프로세스 상태를 PCB에 저장하고 다른 프로세스의 PCB를 불러와서 그 상태로 복구하는 작업 => 문맥 교환의 오버헤드(시간 손실)가 발생하는 이유

- 동기 / 비동기
    - 동기: 요청한 작업이 끝날 때까지 기다림.
    - 비동기: 작업 요청 후 기다리지 않고 다음 작업 수행.

- 동기(Synchronous): 요청을 보내고 결과가 돌아올 때까지 기다린다
    - 요청한 작업이 끝나야 그다음 동작을 함
    - 블로킹 방식이 많음 (멈춰서 기다림)
    - 직관적이고 단순함, 처리 속도는 느릴 수 있음 (대기 시간 발생)

- 비동기(Asynchronous): 요청을 보내고 바로 다음 작업을 진행한다
    - 결과가 오면 나중에 따로 처리
    - 논블로킹 방식이 많음 (멈추지 않고 진행)
    - 빠른 처리가 가능, 복잡도는 상대적으로 높음 (콜백, 이벤트 처리 등)

- 이벤트 리스너(Event Listener): 이벤트가 발생하면 실행되는 함수(핸들러)를 등록해 놓는 것
    - 이벤트가 발생할 때까지 대기 상태

- 콜백 함수(Callback Function): 다른 함수에 인자로 전달되어, 특정 시점에 실행되는 함수
    - 비동기 처리에서 자주 사용

- 비동기 처리 흐름 (기본 개념)
    - 기본 순서
        1. 요청 발생: 시간이 오래 걸리는 작업 요청 (예: 서버 요청, 타이머 등)
        2. 메인 로직은 그대로 실행 계속: 기다리지 않고 다음 코드 실행 (논블로킹)
        3. 이벤트가 발생하거나 작업이 완료되면 => 등록한 콜백 함수 또는 이벤트 리스너가 호출됨
        4. 콜백 함수가 호출돼서 후처리 실행
    - 콜백과 이벤트 리스너 차이 흐름
        - 콜백 함수 흐름: 특정 비동기 작업(함수)에 콜백 전달 → 완료되면 콜백 실행
        - 이벤트 리스너 흐름: 특정 이벤트를 리스너에 등록 → 이벤트가 발생하면 실행

- 비동기 요약
    - 콜백은 비동기 함수 완료 후 실행되는 함수
    - 이벤트 리스너는 이벤트가 발생했을 때 반응하는 함수
    - 둘 다 메인 로직과 병렬로 동작해서 프로그램이 멈추지 않음 (비동기)

- 블로킹 / 논블로킹
    - 블로킹: 결과가 나올 때까지 멈춤.
    - 논블로킹: 결과가 나오지 않아도 바로 리턴.

- 데드락(Deadlock)
    - 발생 조건
        - 상호 배제: 하나 이상의 자원을 둘 이상의 프로세스가 이용 불가
        - 점유와 대기: 자원을 점유한 프로세스가 다른 자원을 요청
        - 비선점: 다른 프로세스의 자원을 뺏아올 수 없는 상태
        - 순환 대기: cyclic한 요청 및 대기 구조
    - 예방 방법
        - 상호 배제 부정: 자원을 공유 가능하게 만들기 (현실적으로 어려움)
        - 점유와 대기 부정: 프로세스가 자원을 모두 확보한 후 실행. → 못 하면 대기하지 않고 점유한 자원 반납하고 재시도. (기아 상태, 본인의 우선 순위가 낮아 자원을 기다리며 영원히 실행되지 못하는 상태 발생 위험 있음) => 해결법: Aging 기법으로 우선순위를 점점 높여서 해결
        - 비선점 부정: 자원을 빼앗을 수 있도록 함. → 다른 프로세스가 점유 중이면 자원 강제로 회수하고 다른 작업으로 이동
        - 순환 대기 부정 (자원 순서 지정): 자원에 고유한 순서 번호를 부여하고, 항상 번호가 높은 자원을 먼저 요청하도록 한다. → 순환 대기를 원천적으로 차단 가능
        - 타임아웃 설정: 자원을 획득하지 못한 상태가 일정 시간 이상 지속되면, 자원 점유를 포기하고 다시 시도
        - 은행원 알고리즘 (Banker's Algorithm): 은행이 대출할 때 고객이 파산하지 않을 수준만큼 대출해주는 것처럼 시스템이 안정 상태에서만 자원을 할당하는 방법 (실제 구현 복잡함)





#### 2. 네트워크

- OSI 7계층
    - 물리 → 데이터 링크 → 네트워크 → 전송 → 세션 → 표현 → 응용

1. 물리 계층 (Physical Layer)

- 케이블과 전파, 신호를 다루는 하드웨어 => 우리가 보내는 0과 1의 비트가 전기 신호나 빛 신호로 변환되어 케이블을 타고 이동
- 진짜 선, 리피터, 허브 같은 물리적 장치가 있음. => 와이파이 전파, 랜선 안의 신호 등


2. 데이터 링크 계층 (Data Link Layer)

- 직접 연결된 두 장치 간에 데이터 전송 담당
- 내 컴퓨터 → 스위치 → 라우터처럼 가까운 이웃끼리 통신
- MAC 주소(하드웨어 주소)를 사용해서 목적지 찾음
- 오류가 나면 바로 잡아줌 (CRC로 오류 검출) => 내 컴퓨터가 같은 네트워크 안의 프린터랑 통신할 때


3. 네트워크 계층 (Network Layer)

- 장거리 이동과 경로 선택(라우팅)을 담당
- 데이터를 패킷 단위로 나눠서 전송하고, IP 주소를 보고 어디로 가야 하는지 결정함
- 라우터가 여기에 해당 => 서울에서 부산까지 택배 보낼 때, 어느 고속도로로 갈지 정하는 것


4. 전송 계층 (Transport Layer)

- 종단 간(End-to-End) 통신을 보장!
- 내가 보낸 데이터가 진짜 안전하게 잘 도착했는지 체크
- TCP는 신뢰성(확인, 재전송), UDP는 빠르게만 보내고 신뢰성은 없음
- 예시
    - 카톡 메세지 보낼 때, TCP라면 읽었는지 확인하고,
    - UDP라면 게임 총알처럼 빠르게 보내기만 함


5. 세션 계층 (Session Layer)

- 연결을 유지하고 세션을 관리함!
- 서버와 클라이언트 간의 대화방을 열고 닫는 역할
- 연결이 끊기면 재연결하거나 동기화함


6. 표현 계층 (Presentation Layer)

- 서로 다른 시스템 간 데이터 형식 맞춰주기
- 데이터를 암호화/복호화, 압축하거나 인코딩 변환(EBCDIC → ASCII)
- 포맷을 통일시켜서 잘 읽히게 함


7. 응용 계층 (Application Layer)

- 사용자가 직접 사용하는 프로그램 영역!
- 우리가 쓰는 웹 브라우저(HTTP), 메일(POP, SMTP) 등
- 사용자가 데이터를 보내고 받는 출입구 같은 곳!


- CRC (Cyclic Redundancy Check, 순환 중복 검사): 데이터가 전송 중에 오류가 생겼는지 검사하는 방법
    - 데이터를 전송하기 전에 특정 계산(나눗셈 연산)을 해서 검사 값(Checksum)을 붙여서 보냄.
    - 받는 쪽에서 다시 똑같은 계산을 해봐서 => 검사 값이 같으면 문제 없음, 검사 값이 다르면 데이터가 손상됐다

- EBCDIC → ASCII 변환: 둘 다 문자를 숫자로 변환하는 문자 인코딩 방식
    - ASCII (아스키 코드): 영어 알파벳을 숫자로 변환하는 가장 기본적인 코드
    - EBCDIC (Extended Binary Coded Decimal Interchange Code): IBM이 만든 옛날 인코딩 방식
        - ASCII랑 숫자 매핑이 다름 → 호환 안 됨
    - 서로 다른 시스템(IBM 메인프레임 ↔ PC)이 데이터를 주고받을 때 EBCDIC ↔ ASCII 변환이 필요

- TCP vs UDP
    - TCP
        - 연결 지향: 느리지만 확실하고 안전하게 전달함, 중요 데이터 보내기 전 연결을 먼저 만든다 = 연결 지향(Connection-Oriented)
        - 신뢰성 보장
        - 순서 보장(3-way handshake): TCP에서 서버랑 클라이언트가 서로 약속을 맺는 과정, 서버 클라이언트간 3번 주고받아서(3-way) 연결을 확실하게 만들기 때문에 붙은 이름
    - UDP
        - 비연결(연결 안 함) 방식, 대신 속도가 엄청 빠름
        - 속도 빠름
        - 신뢰성 없음 (스트리밍, DNS 등)

- HTTP vs HTTPS
    - HTTP: HyperText Transfer Protocol의 약자
        - 웹사이트에 접속할 때 쓰는 통신 규칙(프로토콜)
        - 비연결성: 한 번 요청하고 응답이 오면 서버와 연결이 바로 끊김, 요청-응답 단위로만 통신하고, 계속 연결을 유지하지 않음
        - 무상태성: 서버가 클라이언트의 이전 정보를 기억하지 않음
    - HTTPS: HTTP Secure, 즉 보안이 추가된 HTTP
        - SSL/TLS라는 암호화 기술이 추가된 버전
        - 데이터를 암호화해서 안전하게 전송 => 누가 중간에 데이터를 훔쳐가도 내용을 볼 수 없음.
        - SSL/TLS: 데이터를 보낼 때 자물쇠 채워서 보내는 기술, 내 정보(아이디, 비번, 카드번호 등)가 중간에서 해킹당해도 알아볼 수 없게 암호화

- 쿠키 vs 세션
    - 쿠키: 클라이언트 저장, 크기/보안 제한.
        - 클라이언트(사용자 컴퓨터, 브라우저)에 저장하는 데이터 조각
        - 웹사이트가 사용자 정보를 기억하려고 클라이언트 쪽에 저장, 자동 로그인 등에 사용
        - 저장 위치: 클라이언트 (브라우저에 저장됨)
        - 용량 제한: 작음 (4KB 정도)
        - 보안: 노출 위험이 있음 (클라이언트에 저장되어서 조작 가능)
        - 사용 예시: 자동 로그인, 장바구니 정보 저장
    - 세션: 서버 저장, 상대적으로 보안이 좋음.
        - 서버가 사용자별로 따로 정보를 관리하는 방식
        - 사용자가 로그인하면 서버가 서버에 정보를 저장하고 세션 ID를 사용자한테 줌 → 사용자는 다음 요청에 이 ID만 보내면 됨
        - 저장 위치: 서버 (서버 메모리에 저장)
        - 용량 제한: 서버 성능에 따라 다름
        - 보안: 서버에서 관리하니까 상대적으로 안전
        - 사용 예시: 로그인 유지, 사용자 정보 보호

- DNS 동작 과정
    - 브라우저에 도메인 주소 입력 => 컴퓨터는 이걸 보고 IP 주소를 알아내야 서버에 연결할 수 있음.
    - 먼저 로컬 캐시 확인 => 예전에 접속했던 기록이 있다면 → 바로 IP 주소 반환 => 없으면? → DNS 서버에게 물어봄
    - DNS 서버(네임서버)에 요청 => 내가 속한 인터넷 제공업체(ISP)의 DNS 서버가 첫 번째로 받음 => 이 서버가 모르겠으면 상위 DNS 서버에 요청을 보냄.
    - 계층 구조로 상위 네임서버에 차례차례 문의 => 루트 네임서버 → .com 네임서버 → naver.com 네임서버 순으로 진행
    - 마지막 권한 DNS 서버가 최종 IP 주소를 알려줌
    - 받은 IP 주소로 접속 => 이제 브라우저가 ip 주소에 접속함

- Domain Name: 사람이 보기 쉬운 주소 (www.naver.com)
- IP 주소: 컴퓨터가 통신하는 숫자 주소 (125.209.222.141)
- DNS 서버(네임서버): 이름을 IP로 바꿔주는 서버
- 계층적 구조: 루트 → 최상위(TLD) → 권한(Authoritative)

- DNS 공격 & 보안 개념
    - DNS 스푸핑: 가짜 IP 주소를 응답하여 사용자를 피싱 사이트로 유도
    - DNS 캐싱 포이즈닝: DNS 서버 캐시에 악성 데이터를 저장시켜서 잘못된 IP로 연결 유도
    - HTTPS가 중요한 이유와도 연결

- 로드 밸런싱 (Load Balancing): 서버 트래픽을 여러 서버에 분산
    - L4 (전송 계층)
        - 네트워크 계층(전송 계층)에서 분산
        - 클라이언트 IP, 포트 기반
        - 빠르지만 단순함, AWS ELB (네트워크 로드 밸런서)
    - L7 로드 밸런서
        - 애플리케이션 계층에서 분산
        - URL, 쿠키, 헤더 기반으로 분산 가능

- REST API 개념
    - REST (Representational State Transfer)
        - 자원을 URI로 식별하고, 상태는 HTTP 메서드(GET, POST 등)로 처리
        - 무상태성, 클라이언트-서버 구조 원칙




#### 3. 자료구조

- 배열 vs 연결 리스트
    - 배열: 인덱스 접근 O(1), 크기 고정.
    - 연결 리스트: 삽입/삭제 O(1), 탐색 O(n).

- 스택 / 큐
    - 스택: LIFO (후입선출), DFS.
    - 큐: FIFO (선입선출), BFS.

- 힙 (Heap)
    - 최소/최대 힙: 우선순위 큐 구현, 삽입/삭제 O(log n).
    - 트리 / 이진 탐색 트리트리: 계층적 자료구조.
    - 탐색은 느림

- BST (이진 탐색 트리: Binary Search Tree): 왼쪽 < 루트 < 오른쪽, 탐색 O(log n).
    - 왼쪽 자식은 루트보다 작고, 오른쪽 자식은 루트보다 큰 구조를 유지하는 트리
    - 탐색이 빠름 => 정렬된 형태 유지하기 때문에 => 탐색, 삽입, 삭제 모두 평균 O(log n) 시간
    - 단점: 한쪽으로 편향되면 성능이 떨어질 수 있음 최악 O(n)

- 그래프 / DFS / BFS
    - 그래프: 정점과 간선으로 구성.
    - DFS: 깊이 우선 탐색, 스택/재귀 사용.
    - BFS: 너비 우선 탐색, 큐 사용.

- 해시테이블
    - 키를 해시함수로 변환하여 인덱스에 저장.
    - 평균 검색 O(1), 충돌 해결 (체이닝, 개방 주소법).


#### 4. 알고리즘

1. 정렬

- 퀵 정렬: 분할 정복, 평균 O(n log n), 최악 O(n^2), 불안정.
- 머지 정렬: 항상 O(n log n), 안정 정렬.
- 힙 정렬: O(n log n), 불안정.


2. 탐색
    - 이진 탐색: 정렬된 데이터에서 중간값과 비교, O(log n).


3. 동적 계획법 

- (DP)부분 문제 저장 → 중복 계산 방지.
    - 탑다운: 재귀 + 메모이제이션.
    - 바텀업: 반복문으로 테이블 채움.


4. LIS (최장 증가 부분 수열)
    - 기본 DP: O(n^2)
    - 이진탐색(lower_bound): O(n log n)


5. 최소 공통 조상 (LCA)
    - 깊이 맞추고, 2^i 부모로 점프 (Binary Lifting).
    - 전처리 O(n log n), 쿼리 O(log n)


#### 5. 데이터베이스(DB)

- 트랜잭션과 ACID
    - 트랜잭션: 데이터베이스에서 작업의 최소 단위, 여러 작업이 하나의 덩어리로 묶여서, 모두 성공하거나, 하나라도 실패하면 전부 취소
    - 원자성 (Atomicity): 트랜잭션은 모두 실행되거나, 아예 안 되거나 둘 중 하나, 중간에 실패하면 전부 취소하고 롤백(Rollback)
    - 일관성 (Consistency): 트랜잭션 수행 전후에 데이터의 무결성이 유지되어야 함 => 규칙이나 제약조건을 어기지 않게!
    - 격리성 (Isolation): 동시에 여러 트랜잭션이 실행될 때 → 서로 영향을 주지 않고 독립적으로 실행되어야 함 => 다른 트랜잭션의 중간 결과를 보면 안 됨 => 동시성 제어 필요 (락 등 사용)
    - 지속성 (Durability): 트랜잭션이 커밋(Commit)되면 결과는 영구적으로 저장, 시스템이 고장나도 결과가 유지됨

- 트랜잭션 격리 수준 (Isolation Level)
    - Read Uncommitted: 커밋 안 된 것도 읽기 (가장 낮은 격리) => Dirty Read: 트랜잭션이 아직 확정(커밋)되지 않은 값을 읽음 → 롤백되면 데이터가 잘못됨
    - Read Committed: 커밋된 데이터만 읽음 => Non-Repeatable Read: 처음 읽은 후에, 다른 트랜잭션이 값을 바꿔버려서 같은 데이터를 다시 읽었더니 값이 달라질 수 잇음.
    - Repeatable Read: 트랜잭션 동안 동일 데이터 반복 보장 => Phantom Read: 조건에 맞는 새로운 행이 삽입/삭제돼서 동일한 쿼리를 다시 실행하면 결과 행 수가 바뀔 수 있음.
    - Serializable: 완전 직렬화 (가장 높은 격리) => 없음 (성능 저하)


- 인덱스
    - 덱스는 자료구조를 사용해서 데이터를 정렬하고 관리 => 대부분의 인덱스는 B+ 트리를 사용해서 효율적으로 찾음 => 데이터가 정렬돼 있어서 이진 탐색처럼 빠르게 이동 가능

- B- 트리
    - 다단계로 나뉜 균형 이진 탐색 트리(다진 트리)
    - 각 노드가 여러 개의 키와 포인터를 가짐
    - 데이터와 인덱스를 모두 내부 노드와 리프 노드에 저장 → 검색할 때 데이터가 내부 노드에도 있을 수 있고, 리프 노드에도 있을 수 있음 → 그래서 데이터가 흩어져 있어서 접근 속도가 다소 일정하지 않을 수 있음

- B+ 트리
    - B-트리에서 업그레이드 된 형태!
    - 데이터는 오직 리프 노드에만 저장
    - 내부 노드는 인덱스(키 값)만 저장해서 탐색 경로가 더 간단하고 일정함
    - 리프 노드가 연결 리스트처럼 연결되어 있어서 범위 검색이 빠름 -> 그래서 데이터베이스 인덱스에 가장 많이 사용됨

- B+ 트리로 인덱스를 쓰는 이유
    - 데이터가 전부 리프 노드에 있어서 탐색이 빠르고 일정
    - 범위 검색이 매우 효율적 (리프 노드가 순서대로 연결돼 있음)

- 정규화 vs 비정규화
    - 정규화
        - 중복 데이터를 최소화하고, 데이터 무결성 유지가 목적
        - 데이터베이스를 효율적으로 설계하는 방법
        - 테이블을 잘게 쪼갬 → 각각의 테이블이 단일한 의미만 가짐
        - 업데이트, 삽입, 삭제 시 오류 방지
    - 비정규화
        - 정규화된 테이블을 다시 통합하거나 중복을 허용하는 작업
        - 속도(성능) 향상이 목표 => 조인을 자주 해야 할 경우, 조인 비용이 커지니까 데이터를 합쳐서 저장하는 것
        - 읽기 작업이 많고 빠른 속도가 필요할 때 사용
        - 정규화가 지나치면 조인 연산이 많아져서 느려질 수 있고, 성능을 높이기 위해 약간의 중복을 허용하고 테이블을 합치기도 함

- 조인
    - INNER JOIN: 교집합.
    - OUTER JOIN: 한쪽 데이터 전부 가져옴.


#### 6. 컴퓨터 구조

- 메모리 계층 구조
    - 레지스터 → 캐시 → 메인 메모리 → 하드디스크.
    - 가까울수록 빠르고 비싸다.


- 캐시 메모리지역성의 원칙
    - 메모리 접근 패턴을 예측해서 효율적으로 데이터를 캐시에 저장하는 것
    - 시간 지역성(Temporal Locality): 최근에 사용한 데이터는 곧 또 사용될 가능성이 높다 => 그래서 한 번 가져온 데이터를 캐시에 저장하고 빠르게 다시 사용함
    - 공간 지역성(Spatial Locality): 지금 접근한 데이터 근처에 있는 데이터도 곧 사용할 가능성이 높다 => 예를 들어, 배열을 순서대로 읽는 경우 → 한 번에 묶어서 캐시에 저장
    - CPU와 메모리 사이 속도 차이를 완화하기 위해 사용

- 캐시 계층 구조
    - L1 캐시: CPU 내부, 가장 빠르고 작음 (용량 작음)
    - L2 캐시: CPU 내부 또는 외부, L1보다 느리지만 더 큼
    - L3 캐시: 멀티코어 CPU에서 공유, 느리지만 용량 큼

- 캐시가 없다면: CPU가 매번 메모리를 기다려야 해서 작업 속도가 크게 느려짐

- 가상 메모리: RAM(물리 메모리)가 부족하면 하드디스크 일부 공간을 메모리처럼 사용함
    - 페이징(Paging)과 세그멘테이션(Segmentation) 기법을 통해 가능
    - 필요한 메모리 공간만 조각내서 관리하고, 자주 안 쓰는 건 디스크로 옮김(Swap)
    - CPU가 다시 필요하면 하드디스크에서 메모리로 가져옴(페이지 폴트)

- 페이징 vs 세그멘테이션 (가상 메모리 관리 기법)
    - 페이징(Paging)
        - 고정 크기로 메모리를 나눔 (Page)
        - 외부 단편화 없음
        - 내부 단편화 존재 가능
    - 세그멘테이션(Segmentation)
        - 가변 크기로 메모리를 나눔 (Segment)
        - 프로그램 논리 단위에 따라 분할
        - 외부 단편화 발생 가능

- 캐시와 가상 메모리 차이
    - 목적: CPU와 메모리 속도 차이 완화 / 실제 메모리 부족 해결
    - 저장 위치: CPU와 메모리 사이 / 하드디스크와 메모리 사이
    - 주 기능: 자주 쓰는 데이터 미리 저장 / 물리 메모리 확장



#### 7. 기타 개념

- 시간 복잡도
    - O(1), O(log n), O(n), O(n log n), O(n^2)

- Stable / Unstable Sort
    - Stable: 같은 값이면 순서 유지 (머지, 버블).
    - Unstable: 순서 보장 안 함 (퀵, 힙).

- 해시 함수와 충돌 해결체이닝(리스트 연결), 개방 주소법(빈 공간 탐색).










